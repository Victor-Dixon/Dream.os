"""
Financial Analytics Data Manager - V2 Compliant Data Persistence

This module handles data persistence, loading, and management for financial analytics.
Follows V2 standards with â‰¤200 LOC and single responsibility for data management.
"""

import json
import logging

from src.utils.stability_improvements import stability_manager, safe_import
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import asdict

from .data_models import BacktestResult, PerformanceMetrics, RiskAnalysis

logger = logging.getLogger(__name__)


class DataManager:
    """Manages data persistence and loading for financial analytics"""
    
    def __init__(self, data_dir: str = "financial_analytics"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # File paths
        self.results_file = self.data_dir / "backtest_results.json"
        self.metrics_file = self.data_dir / "performance_metrics.json"
        self.risk_file = self.data_dir / "risk_analyses.json"
    
    def save_backtest_results(self, results: List[BacktestResult]) -> bool:
        """Save backtest results to file"""
        try:
            results_data = []
            for result in results:
                result_dict = asdict(result)
                # Convert datetime objects to ISO format
                if result_dict.get("start_date"):
                    result_dict["start_date"] = result.start_date.isoformat()
                if result_dict.get("end_date"):
                    result_dict["end_date"] = result.end_date.isoformat()
                if result_dict.get("timestamp"):
                    result_dict["timestamp"] = result.timestamp.isoformat()
                results_data.append(result_dict)
            
            with open(self.results_file, "w") as f:
                json.dump(results_data, f, indent=2, default=str)
            
            logger.info(f"Saved {len(results)} backtest results")
            return True
        except Exception as e:
            logger.error(f"Error saving backtest results: {e}")
            return False
    
    def load_backtest_results(self) -> List[BacktestResult]:
        """Load backtest results from file"""
        try:
            if not self.results_file.exists():
                logger.info("No backtest results file found")
                return []
            
            with open(self.results_file, "r") as f:
                results_data = json.load(f)
            
            results = []
            for result_data in results_data:
                try:
                    # Convert ISO format strings back to datetime objects
                    if "start_date" in result_data:
                        result_data["start_date"] = datetime.fromisoformat(
                            result_data["start_date"]
                        )
                    if "end_date" in result_data:
                        result_data["end_date"] = datetime.fromisoformat(
                            result_data["end_date"]
                        )
                    if "timestamp" in result_data:
                        result_data["timestamp"] = datetime.fromisoformat(
                            result_data["timestamp"]
                        )
                    
                    result = BacktestResult(**result_data)
                    results.append(result)
                except Exception as e:
                    logger.warning(f"Skipping invalid result data: {e}")
                    continue
            
            logger.info(f"Loaded {len(results)} backtest results")
            return results
        except Exception as e:
            logger.error(f"Error loading backtest results: {e}")
            return []
    
    def save_performance_metrics(self, metrics: Dict[str, PerformanceMetrics]) -> bool:
        """Save performance metrics to file"""
        try:
            metrics_data = {}
            for name, metric in metrics.items():
                try:
                    metrics_data[name] = {
                        "returns": metric.returns.tolist() if hasattr(metric.returns, 'tolist') else [],
                        "cumulative_returns": metric.cumulative_returns.tolist() if hasattr(metric.cumulative_returns, 'tolist') else [],
                        "drawdown": metric.drawdown.tolist() if hasattr(metric.drawdown, 'tolist') else [],
                        "value_at_risk": metric.value_at_risk,
                        "conditional_var": metric.conditional_var,
                        "sharpe_ratio": getattr(metric, 'sharpe_ratio', 0.0),
                        "sortino_ratio": getattr(metric, 'sortino_ratio', 0.0),
                        "calmar_ratio": getattr(metric, 'calmar_ratio', 0.0),
                        "information_ratio": getattr(metric, 'information_ratio', 0.0),
                        "treynor_ratio": getattr(metric, 'treynor_ratio', 0.0),
                        "jensen_alpha": getattr(metric, 'jensen_alpha', 0.0),
                        "tracking_error": getattr(metric, 'tracking_error', 0.0),
                        "correlation": getattr(metric, 'correlation', 0.0),
                    }
                except Exception as e:
                    logger.warning(f"Skipping invalid metric {name}: {e}")
                    continue
            
            with open(self.metrics_file, "w") as f:
                json.dump(metrics_data, f, indent=2, default=str)
            
            logger.info(f"Saved {len(metrics)} performance metrics")
            return True
        except Exception as e:
            logger.error(f"Error saving performance metrics: {e}")
            return False
    
    def load_performance_metrics(self) -> Dict[str, Dict[str, Any]]:
        """Load performance metrics from file"""
        try:
            if not self.metrics_file.exists():
                logger.info("No performance metrics file found")
                return {}
            
            with open(self.metrics_file, "r") as f:
                metrics_data = json.load(f)
            
            logger.info(f"Loaded {len(metrics_data)} performance metrics")
            return metrics_data
        except Exception as e:
            logger.error(f"Error loading performance metrics: {e}")
            return {}
    
    def save_risk_analyses(self, risk_analyses: Dict[str, RiskAnalysis]) -> bool:
        """Save risk analyses to file"""
        try:
            risk_data = {}
            for name, risk in risk_analyses.items():
                try:
                    risk_data[name] = asdict(risk)
                except Exception as e:
                    logger.warning(f"Skipping invalid risk analysis {name}: {e}")
                    continue
            
            with open(self.risk_file, "w") as f:
                json.dump(risk_data, f, indent=2, default=str)
            
            logger.info(f"Saved {len(risk_analyses)} risk analyses")
            return True
        except Exception as e:
            logger.error(f"Error saving risk analyses: {e}")
            return False
    
    def load_risk_analyses(self) -> Dict[str, Dict[str, Any]]:
        """Load risk analyses from file"""
        try:
            if not self.risk_file.exists():
                logger.info("No risk analyses file found")
                return {}
            
            with open(self.risk_file, "r") as f:
                risk_data = json.load(f)
            
            logger.info(f"Loaded {len(risk_data)} risk analyses")
            return risk_data
        except Exception as e:
            logger.error(f"Error loading risk analyses: {e}")
            return {}
    
    def save_all_data(self, results: List[BacktestResult], 
                     metrics: Dict[str, PerformanceMetrics],
                     risk_analyses: Dict[str, RiskAnalysis]) -> bool:
        """Save all financial analytics data"""
        try:
            success = True
            success &= self.save_backtest_results(results)
            success &= self.save_performance_metrics(metrics)
            success &= self.save_risk_analyses(risk_analyses)
            
            if success:
                logger.info("All financial analytics data saved successfully")
            else:
                logger.warning("Some data failed to save")
            
            return success
        except Exception as e:
            logger.error(f"Error saving all data: {e}")
            return False
    
    def load_all_data(self) -> tuple[List[BacktestResult], Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]:
        """Load all financial analytics data"""
        try:
            results = self.load_backtest_results()
            metrics = self.load_performance_metrics()
            risk_analyses = self.load_risk_analyses()
            
            logger.info("All financial analytics data loaded successfully")
            return results, metrics, risk_analyses
        except Exception as e:
            logger.error(f"Error loading all data: {e}")
            return [], {}, {}
    
    def clear_all_data(self) -> bool:
        """Clear all saved data files"""
        try:
            files_to_remove = [self.results_file, self.metrics_file, self.risk_file]
            for file_path in files_to_remove:
                if file_path.exists():
                    file_path.unlink()
                    logger.info(f"Removed {file_path}")
            
            logger.info("All financial analytics data cleared")
            return True
        except Exception as e:
            logger.error(f"Error clearing data: {e}")
            return False

