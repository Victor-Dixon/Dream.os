#!/usr/bin/env python3
"""
Quality Validation Orchestrator
===============================
Enterprise-grade quality validation orchestration system.
Target: 300 LOC, Maximum: 350 LOC.
Focus: System integration, quality management, enterprise standards enforcement.
"""

import os
import sys
import time
import json
import threading

from src.utils.stability_improvements import stability_manager, safe_import
from pathlib import Path
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass, asdict
from src.services.config_utils import ConfigLoader

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import quality systems
try:
    from services.automated_quality_gates import AutomatedQualityGates
    from services.continuous_quality_monitor import ContinuousQualityMonitor
    from services.enterprise_quality_assurance import EnterpriseQualityAssurance
except ImportError as e:
    print(f"Import warning: {e}")
    # Fallback mock services for orchestration
    AutomatedQualityGates = None
    ContinuousQualityMonitor = None
    EnterpriseQualityAssurance = None


@dataclass
class QualityValidationResult:
    """Comprehensive quality validation result"""

    validation_id: str
    timestamp: float
    overall_score: float
    quality_grade: str
    gate_results: Dict
    monitoring_status: Dict
    recommendations: List[str]
    compliance_status: str


class QualityValidationOrchestrator:
    """Quality validation orchestrator for enterprise standards management"""

    def __init__(self, config_path: str = "quality_orchestrator_config.json"):
        """Initialize quality validation orchestrator"""
        self.config_path = config_path
        default_config = {
            "orchestration": {
                "enabled": True,
                "validation_interval": 600,  # 10 minutes
                "compliance_tracking": True,
                "auto_remediation": False,
            },
            "quality_gates": {
                "enforce_all_gates": True,
                "strict_mode": True,
                "auto_reject_threshold": 70.0,
            },
            "monitoring": {
                "continuous_monitoring": True,
                "alert_integration": True,
                "trend_analysis": True,
            },
            "enterprise_standards": {
                "loc_compliance": True,
                "code_quality": True,
                "test_coverage": True,
                "documentation": True,
            },
        }
        self.config = ConfigLoader.load(self.config_path, default_config)
        self.quality_gates = None
        self.quality_monitor = None
        self.enterprise_qa = None
        self.orchestration_active = False
        self.validation_history = []
        self.compliance_tracking = {}

        # Initialize quality systems
        self._initialize_quality_systems()

        # Validation callbacks
        self.validation_callbacks = []


    def _initialize_quality_systems(self):
        """Initialize all quality systems"""
        print("üîß Initializing quality systems...")

        # Initialize quality gates
        if AutomatedQualityGates:
            try:
                self.quality_gates = AutomatedQualityGates()
                print("‚úÖ Quality gates system initialized")
            except Exception as e:
                print(f"‚ùå Quality gates initialization failed: {e}")

        # Initialize quality monitor
        if ContinuousQualityMonitor:
            try:
                self.quality_monitor = ContinuousQualityMonitor()
                print("‚úÖ Quality monitor system initialized")
            except Exception as e:
                print(f"‚ùå Quality monitor initialization failed: {e}")

        # Initialize enterprise QA
        if EnterpriseQualityAssurance:
            try:
                self.enterprise_qa = EnterpriseQualityAssurance()
                print("‚úÖ Enterprise QA system initialized")
            except Exception as e:
                print(f"‚ùå Enterprise QA initialization failed: {e}")

        print("üîß Quality systems initialization completed")

    def start_orchestration(self, directory_path: str = None) -> bool:
        """Start quality validation orchestration"""
        if self.orchestration_active:
            print("‚ö†Ô∏è  Orchestration already active")
            return False

        if not directory_path:
            directory_path = os.getcwd()

        print(f"üöÄ Starting quality validation orchestration for: {directory_path}")

        # Start quality monitoring if available
        if self.quality_monitor:
            self.quality_monitor.start_monitoring(directory_path)

        # Start orchestration thread
        self.orchestration_active = True
        self.orchestration_thread = threading.Thread(
            target=self._orchestration_loop, args=(directory_path,), daemon=True
        )
        self.orchestration_thread.start()

        print("‚úÖ Quality validation orchestration started")
        return True

    def stop_orchestration(self) -> bool:
        """Stop quality validation orchestration"""
        if not self.orchestration_active:
            print("‚ö†Ô∏è  Orchestration not active")
            return False

        print("üõë Stopping quality validation orchestration...")
        self.orchestration_active = False

        # Stop quality monitoring
        if self.quality_monitor:
            self.quality_monitor.stop_monitoring()

        # Stop orchestration thread
        if (
            hasattr(self, "orchestration_thread")
            and self.orchestration_thread.is_alive()
        ):
            self.orchestration_thread.join(timeout=5)

        print("‚úÖ Quality validation orchestration stopped")
        return True

    def _orchestration_loop(self, directory_path: str):
        """Main orchestration loop"""
        while self.orchestration_active:
            try:
                # Perform comprehensive validation
                validation_result = self._perform_comprehensive_validation(
                    directory_path
                )

                # Store in history
                self.validation_history.append(validation_result)

                # Update compliance tracking
                self._update_compliance_tracking(validation_result)

                # Trigger validation callbacks
                self._trigger_validation_callbacks(validation_result)

                # Wait for next validation cycle
                time.sleep(self.config["orchestration"]["validation_interval"])

            except Exception as e:
                print(f"‚ùå Orchestration error: {e}")
                time.sleep(60)  # Wait 1 minute on error

    def _perform_comprehensive_validation(
        self, directory_path: str
    ) -> QualityValidationResult:
        """Perform comprehensive quality validation"""
        print(f"üîç Performing comprehensive quality validation for: {directory_path}")

        validation_id = f"VALIDATION-{int(time.time())}"
        timestamp = time.time()

        # Run quality gates validation
        gate_results = {}
        if self.quality_gates:
            try:
                gate_validation = self.quality_gates.validate_directory(directory_path)
                gate_results = gate_validation
            except Exception as e:
                gate_results = {"error": str(e)}

        # Get monitoring status
        monitoring_status = {}
        if self.quality_monitor:
            try:
                monitoring_status = self.quality_monitor.get_quality_summary()
            except Exception as e:
                monitoring_status = {"error": str(e)}

        # Calculate overall score
        overall_score = self._calculate_overall_score(gate_results, monitoring_status)
        quality_grade = self._calculate_quality_grade(overall_score)

        # Generate recommendations
        recommendations = self._generate_comprehensive_recommendations(
            gate_results, monitoring_status, overall_score
        )

        # Determine compliance status
        compliance_status = self._determine_compliance_status(
            overall_score, gate_results
        )

        result = QualityValidationResult(
            validation_id=validation_id,
            timestamp=timestamp,
            overall_score=overall_score,
            quality_grade=quality_grade,
            gate_results=gate_results,
            monitoring_status=monitoring_status,
            recommendations=recommendations,
            compliance_status=compliance_status,
        )

        return result

    def _calculate_overall_score(
        self, gate_results: Dict, monitoring_status: Dict
    ) -> float:
        """Calculate overall quality score"""
        scores = []
        weights = []

        # Quality gates score (weight: 0.6)
        if gate_results and not gate_results.get("error"):
            gate_score = gate_results.get("quality_score", 0)
            scores.append(gate_score)
            weights.append(0.6)

        # Monitoring score (weight: 0.4)
        if monitoring_status and not monitoring_status.get("error"):
            monitor_score = monitoring_status.get("average_quality_score", 0)
            scores.append(monitor_score)
            weights.append(0.4)

        # Calculate weighted average
        if scores and weights:
            total_weight = sum(weights)
            weighted_sum = sum(score * weight for score, weight in zip(scores, weights))
            return weighted_sum / total_weight

        return 0.0

    def _calculate_quality_grade(self, score: float) -> str:
        """Calculate quality grade based on score"""
        if score >= 95.0:
            return "A+"
        elif score >= 90.0:
            return "A"
        elif score >= 85.0:
            return "B+"
        elif score >= 80.0:
            return "B"
        elif score >= 75.0:
            return "C+"
        elif score >= 70.0:
            return "C"
        else:
            return "D"

    def _generate_comprehensive_recommendations(
        self, gate_results: Dict, monitoring_status: Dict, overall_score: float
    ) -> List[str]:
        """Generate comprehensive improvement recommendations"""
        recommendations = []

        # Overall score recommendations
        if overall_score < 80.0:
            recommendations.append(
                "Overall quality below enterprise standards - implement improvement plan"
            )
        elif overall_score < 90.0:
            recommendations.append(
                "Quality approaching enterprise standards - focus on remaining improvements"
            )

        # Gate results recommendations
        if gate_results and not gate_results.get("error"):
            failed_files = gate_results.get("failed_files", 0)
            if failed_files > 0:
                recommendations.append(
                    f"Address {failed_files} failed quality validations"
                )

        # Monitoring recommendations
        if monitoring_status and not monitoring_status.get("error"):
            if monitoring_status.get("alert_summary", {}).get("critical_alerts", 0) > 0:
                recommendations.append("Address critical quality alerts immediately")

            if monitoring_status.get("alert_summary", {}).get("high_alerts", 0) > 2:
                recommendations.append(
                    "Implement quality improvement plan to reduce high-severity alerts"
                )

        # Enterprise standards recommendations
        if overall_score < 85.0:
            recommendations.extend(
                [
                    "Focus on LOC compliance improvements",
                    "Enhance code quality and documentation",
                    "Improve test coverage and quality",
                ]
            )

        if not recommendations:
            recommendations.append(
                "Quality meets enterprise standards - maintain current practices"
            )

        return recommendations

    def _determine_compliance_status(
        self, overall_score: float, gate_results: Dict
    ) -> str:
        """Determine overall compliance status"""
        if overall_score >= 90.0:
            return "FULLY_COMPLIANT"
        elif overall_score >= 80.0:
            return "MOSTLY_COMPLIANT"
        elif overall_score >= 70.0:
            return "PARTIALLY_COMPLIANT"
        else:
            return "NON_COMPLIANT"

    def _update_compliance_tracking(self, validation_result: QualityValidationResult):
        """Update compliance tracking metrics"""
        timestamp = validation_result.timestamp
        score = validation_result.overall_score
        status = validation_result.compliance_status

        # Update compliance history
        if "compliance_history" not in self.compliance_tracking:
            self.compliance_tracking["compliance_history"] = []

        self.compliance_tracking["compliance_history"].append(
            {
                "timestamp": timestamp,
                "score": score,
                "status": status,
                "validation_id": validation_result.validation_id,
            }
        )

        # Keep only last 100 entries
        if len(self.compliance_tracking["compliance_history"]) > 100:
            self.compliance_tracking["compliance_history"] = self.compliance_tracking[
                "compliance_history"
            ][-100:]

        # Update compliance statistics
        self.compliance_tracking["current_status"] = status
        self.compliance_tracking["current_score"] = score
        self.compliance_tracking["last_validation"] = timestamp
        self.compliance_tracking["total_validations"] = len(
            self.compliance_tracking["compliance_history"]
        )

    def _trigger_validation_callbacks(self, validation_result: QualityValidationResult):
        """Trigger registered validation callbacks"""
        for callback in self.validation_callbacks:
            try:
                callback(validation_result)
            except Exception as e:
                print(f"‚ùå Validation callback error: {e}")

    def register_validation_callback(
        self, callback: Callable[[QualityValidationResult], None]
    ):
        """Register validation callback function"""
        self.validation_callbacks.append(callback)
        print(f"‚úÖ Validation callback registered: {callback.__name__}")

    def get_orchestration_summary(self) -> Dict:
        """Get comprehensive orchestration summary"""
        if not self.validation_history:
            return {"status": "No validations performed"}

        # Calculate summary statistics
        total_validations = len(self.validation_history)
        successful_validations = len(
            [
                v
                for v in self.validation_history
                if v.compliance_status != "NON_COMPLIANT"
            ]
        )

        scores = [v.overall_score for v in self.validation_history]
        average_score = sum(scores) / len(scores) if scores else 0

        # Compliance breakdown
        compliance_breakdown = {}
        for validation in self.validation_history:
            status = validation.compliance_status
            compliance_breakdown[status] = compliance_breakdown.get(status, 0) + 1

        # Get recent trends
        recent_validations = (
            self.validation_history[-10:]
            if len(self.validation_history) >= 10
            else self.validation_history
        )
        trend_direction = "STABLE"
        if len(recent_validations) >= 2:
            recent_scores = [v.overall_score for v in recent_validations]
            if recent_scores[-1] > recent_scores[0]:
                trend_direction = "IMPROVING"
            elif recent_scores[-1] < recent_scores[0]:
                trend_direction = "DECLINING"

        return {
            "orchestration_status": "active"
            if self.orchestration_active
            else "inactive",
            "total_validations": total_validations,
            "successful_validations": successful_validations,
            "success_rate": (successful_validations / total_validations * 100)
            if total_validations > 0
            else 0,
            "average_score": average_score,
            "quality_grade": self._calculate_quality_grade(average_score),
            "compliance_breakdown": compliance_breakdown,
            "trend_direction": trend_direction,
            "compliance_tracking": self.compliance_tracking,
            "last_validation": self.validation_history[-1].timestamp
            if self.validation_history
            else None,
            "orchestration_started": self.validation_history[0].timestamp
            if self.validation_history
            else None,
        }

    def export_orchestration_report(
        self, output_path: str = "quality_orchestration_report.json"
    ):
        """Export comprehensive orchestration report"""
        report = {
            "timestamp": time.time(),
            "system": "Quality Validation Orchestrator",
            "configuration": self.config,
            "orchestration_summary": self.get_orchestration_summary(),
            "validation_history": [
                asdict(v) for v in self.validation_history[-50:]
            ],  # Last 50 entries
            "compliance_tracking": self.compliance_tracking,
            "recommendations": self._generate_orchestration_recommendations(),
        }

        with open(output_path, "w") as f:
            json.dump(report, f, indent=2)

        print(f"üìä Orchestration report exported to: {output_path}")
        return report

    def _generate_orchestration_recommendations(self) -> List[str]:
        """Generate orchestration system recommendations"""
        summary = self.get_orchestration_summary()
        recommendations = []

        if summary.get("average_score", 0) < 80.0:
            recommendations.append(
                "Focus on improving overall quality to meet enterprise compliance standards"
            )

        if summary.get("compliance_breakdown", {}).get("NON_COMPLIANT", 0) > 0:
            recommendations.append(
                "Address non-compliance issues immediately to meet enterprise requirements"
            )

        if summary.get("trend_direction") == "DECLINING":
            recommendations.append(
                "Quality trends declining - implement quality improvement initiatives"
            )

        if not self.orchestration_active:
            recommendations.append(
                "Enable quality orchestration for comprehensive enterprise quality management"
            )

        if not recommendations:
            recommendations.append(
                "Quality orchestration system is performing well - maintain current standards"
            )

        return recommendations


def main():
    """Run quality validation orchestrator"""
    print("üöÄ Quality Validation Orchestrator")
    print("Enterprise Quality Management System")
    print("=" * 50)

    # Initialize orchestrator
    orchestrator = QualityValidationOrchestrator()

    # Start orchestration for current directory
    current_dir = os.getcwd()
    print(f"üîç Starting quality orchestration for: {current_dir}")

    # Start orchestration
    orchestrator.start_orchestration(current_dir)

    # Wait for initial validation
    print("‚è≥ Waiting for initial quality validation...")
    time.sleep(15)

    # Get orchestration summary
    summary = orchestrator.get_orchestration_summary()
    print(f"\nüìä Orchestration Summary:")
    print(f"   Status: {summary['orchestration_status']}")
    print(f"   Total Validations: {summary['total_validations']}")
    print(f"   Success Rate: {summary['success_rate']:.1f}%")
    print(f"   Average Score: {summary['average_score']:.1f}")
    print(f"   Quality Grade: {summary['quality_grade']}")
    print(f"   Trend: {summary['trend_direction']}")

    # Export report
    report = orchestrator.export_orchestration_report()

    print(f"\n‚úÖ Quality validation orchestration started!")
    print(f"üìÅ Report saved to: quality_orchestration_report.json")
    print(f"üîç Orchestrator will continue running in background...")

    return report


if __name__ == "__main__":
    main()
