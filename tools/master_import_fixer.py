#!/usr/bin/env python3
"""
Master Import Fixer - Agent-8
==============================

Comprehensive import error detection and fixing tool.
Uses dependency maps and consolidation mappings to fix all import errors.

<!-- SSOT Domain: qa -->

Author: Agent-8 (Testing & Quality Assurance Specialist)
Date: 2025-12-03
V2 Compliant: Yes (<300 lines)
"""

import ast
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# Load consolidation mappings
CONSOLIDATION_MAP = {
    "test_coverage_tracker": "unified_test_coverage",
    "test_coverage_prioritizer": "unified_test_coverage",
    "analyze_test_coverage_gaps_clean": "unified_test_coverage",
    "test_all_discord_commands": "unified_test_analysis",
}

EXCLUDE_PATTERNS = [
    "__pycache__", ".git", "venv", "env", ".venv",
    "node_modules", "temp_repos", "deprecated"
]


def load_dependency_map() -> Optional[Dict]:
    """Load master dependency map if it exists."""
    maps = [
        Path("docs/organization/PHASE2_AGENT_CELLPHONE_DEPENDENCY_MAP.json"),
        Path("docs/organization/PHASE2_TROOP_DEPENDENCY_MAP.json"),
    ]
    
    for map_path in maps:
        if map_path.exists():
            try:
                return json.loads(map_path.read_text(encoding='utf-8'))
            except Exception:
                pass
    
    return None


def find_python_files(root: Path) -> List[Path]:
    """Find all Python files to scan."""
    files = []
    for py_file in root.rglob("*.py"):
        if not any(pattern in str(py_file) for pattern in EXCLUDE_PATTERNS):
            files.append(py_file)
    return files


def extract_imports_ast(file_path: Path) -> List[Tuple[str, int, str]]:
    """
    Extract imports using AST.
    Returns: [(module, line, full_statement), ...]
    """
    imports = []
    try:
        content = file_path.read_text(encoding='utf-8')
        tree = ast.parse(content, filename=str(file_path))
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append((alias.name, node.lineno, f"import {alias.name}"))
            
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ""
                for alias in node.names:
                    full_import = f"from {module} import {alias.name}"
                    imports.append((f"{module}.{alias.name}", node.lineno, full_import))
    
    except SyntaxError:
        # File has syntax errors, skip AST parsing
        pass
    except Exception:
        pass
    
    return imports


def check_import_valid(import_name: str) -> Tuple[bool, Optional[str]]:
    """Check if an import is valid."""
    try:
        # Try to import
        __import__(import_name.split('.')[0])
        return True, None
    except ImportError as e:
        return False, str(e)
    except Exception:
        return False, "Unknown error"


def find_broken_imports(file_path: Path) -> List[Dict]:
    """Find broken imports in a file."""
    broken = []
    
    # Extract imports using AST
    imports = extract_imports_ast(file_path)
    
    for module, line, statement in imports:
        # Check if it's a consolidated tool
        module_base = module.split('.')[-1]
        if module_base in CONSOLIDATION_MAP:
            broken.append({
                "line": line,
                "old_import": statement,
                "module": module,
                "issue": "consolidated_tool",
                "fix": CONSOLIDATION_MAP[module_base]
            })
            continue
        
        # Check if import is valid
        is_valid, error = check_import_valid(module)
        if not is_valid:
            broken.append({
                "line": line,
                "old_import": statement,
                "module": module,
                "issue": "missing_module",
                "error": error
            })
    
    return broken


def fix_file_imports(file_path: Path, broken: List[Dict], dry_run: bool = True) -> bool:
    """Fix imports in a file."""
    if not broken:
        return False
    
    try:
        content = file_path.read_text(encoding='utf-8')
        lines = content.split('\n')
        
        # Sort by line number (descending) to fix from bottom up
        broken_sorted = sorted(broken, key=lambda x: x['line'], reverse=True)
        
        for issue in broken_sorted:
            line_idx = issue['line'] - 1
            if line_idx >= len(lines):
                continue
            
            old_line = lines[line_idx]
            
            if issue['issue'] == 'consolidated_tool':
                # Fix consolidated tool import
                new_tool = issue['fix']
                # Replace old tool name with new tool name
                new_line = re.sub(
                    rf"\b{re.escape(issue['module'].split('.')[-1])}\b",
                    new_tool,
                    old_line
                )
                lines[line_idx] = new_line
            elif issue['issue'] == 'missing_module':
                # Can't auto-fix missing modules, just mark
                pass
        
        if not dry_run:
            file_path.write_text('\n'.join(lines), encoding='utf-8')
        
        return True
    
    except Exception as e:
        print(f"âš ï¸  Error fixing {file_path}: {e}")
        return False


def main():
    """Main entry point."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Master Import Fixer - Fix all import errors"
    )
    parser.add_argument(
        "--root",
        type=Path,
        default=Path(__file__).parent.parent,
        help="Root directory to scan"
    )
    parser.add_argument(
        "--execute",
        action="store_true",
        help="Actually fix files (default is dry-run)"
    )
    parser.add_argument(
        "--file",
        type=Path,
        help="Fix a specific file"
    )
    parser.add_argument(
        "--report",
        type=Path,
        help="Save report to JSON file"
    )
    
    args = parser.parse_args()
    
    print("ðŸ” MASTER IMPORT FIXER")
    print("=" * 80)
    print(f"Mode: {'DRY RUN' if not args.execute else 'EXECUTING'}")
    print(f"Root: {args.root}\n")
    
    # Load dependency map
    dep_map = load_dependency_map()
    if dep_map:
        print(f"âœ… Loaded dependency map")
    else:
        print(f"âš ï¸  No dependency map found (continuing anyway)\n")
    
    # Find files
    if args.file:
        files = [args.file] if args.file.exists() else []
    else:
        files = find_python_files(args.root)
    
    print(f"ðŸ“ Scanning {len(files)} files...\n")
    
    # Scan for broken imports
    all_broken = []
    files_with_issues = []
    
    for file_path in files:
        broken = find_broken_imports(file_path)
        if broken:
            files_with_issues.append({
                "file": str(file_path),
                "issues": broken
            })
            all_broken.extend(broken)
    
    # Report findings
    if not files_with_issues:
        print("âœ… No import errors found!")
        return 0
    
    print(f"ðŸ“Š Found {len(files_with_issues)} files with import issues:\n")
    
    consolidated_count = sum(
        1 for issue in all_broken
        if issue['issue'] == 'consolidated_tool'
    )
    missing_count = sum(
        1 for issue in all_broken
        if issue['issue'] == 'missing_module'
    )
    
    print(f"   Consolidated tool imports: {consolidated_count}")
    print(f"   Missing modules: {missing_count}\n")
    
    # Show details
    for file_info in files_with_issues[:10]:  # Show first 10
        print(f"ðŸ“ {file_info['file']}")
        for issue in file_info['issues']:
            if issue['issue'] == 'consolidated_tool':
                print(f"   Line {issue['line']}: {issue['old_import']}")
                print(f"   â†’ Fix: Use {issue['fix']}")
            elif issue['issue'] == 'missing_module':
                print(f"   Line {issue['line']}: {issue['old_import']}")
                print(f"   â†’ Error: {issue.get('error', 'Unknown')}")
        print()
    
    if len(files_with_issues) > 10:
        print(f"   ... and {len(files_with_issues) - 10} more files\n")
    
    # Fix files
    if args.execute:
        print("ðŸ”§ Fixing files...\n")
        fixed_count = 0
        for file_info in files_with_issues:
            file_path = Path(file_info['file'])
            if fix_file_imports(file_path, file_info['issues'], dry_run=False):
                fixed_count += 1
        print(f"âœ… Fixed {fixed_count} files!")
    else:
        print(f"ðŸ’¡ Run with --execute to fix {consolidated_count} consolidated tool imports")
    
    # Save report
    if args.report:
        report = {
            "total_files_scanned": len(files),
            "files_with_issues": len(files_with_issues),
            "total_issues": len(all_broken),
            "consolidated_tool_issues": consolidated_count,
            "missing_module_issues": missing_count,
            "files": files_with_issues
        }
        args.report.write_text(json.dumps(report, indent=2), encoding='utf-8')
        print(f"ðŸ“„ Report saved to: {args.report}")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

