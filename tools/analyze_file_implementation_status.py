#!/usr/bin/env python3
"""
Analyze File Implementation Status
===================================

Checks if files are:
- Planned features not yet integrated
- Incomplete implementations
- Referenced in documentation/roadmaps
- Part of future functionality

Author: Agent-5 (Business Intelligence Specialist)
Date: 2025-12-01
Priority: HIGH - Determine if files should be integrated vs deleted
"""

import ast
import json
import re
from pathlib import Path
from typing import Any, Dict, List, Set, Optional


class FileImplementationAnalyzer:
    """Analyze files to determine if they need implementation/integration."""

    def __init__(self, src_root: str = "src", project_root: str = "."):
        """Initialize analyzer."""
        self.src_root = Path(src_root)
        self.project_root = Path(project_root)
        self.results: Dict[str, Dict[str, Any]] = {}
        
    def analyze_file_content(self, file_path: Path) -> Dict[str, Any]:
        """Analyze file content for implementation status indicators."""
        result = {
            "file_path": str(file_path),
            "relative_path": str(file_path.relative_to(self.src_root)),
            "implementation_status": "unknown",
            "indicators": {
                "has_todos": [],
                "has_fixmes": [],
                "has_plans": [],
                "has_incomplete": [],
                "has_stubs": False,
                "has_docstrings": False,
                "line_count": 0,
                "class_count": 0,
                "function_count": 0,
                "implemented_functions": 0,
            },
            "recommendation": "REVIEW_NEEDED",
            "integration_needed": False,
        }
        
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.splitlines()
                result["indicators"]["line_count"] = len(lines)
            
            # Check for TODOs
            todos = re.findall(r'TODO[:\s]+(.+)', content, re.IGNORECASE)
            if todos:
                result["indicators"]["has_todos"] = [t.strip() for t in todos[:5]]
                result["recommendation"] = "NEEDS_IMPLEMENTATION"
                result["integration_needed"] = True
            
            # Check for FIXMEs
            fixmes = re.findall(r'FIXME[:\s]+(.+)', content, re.IGNORECASE)
            if fixmes:
                result["indicators"]["has_fixmes"] = [f.strip() for f in fixmes[:5]]
                result["recommendation"] = "NEEDS_IMPLEMENTATION"
                result["integration_needed"] = True
            
            # Check for planned features
            plan_keywords = [
                r'plan[n]?[e]?d',
                r'future',
                r'upcoming',
                r'roadmap',
                r'soon',
                r'next',
            ]
            for keyword in plan_keywords:
                matches = re.findall(rf'{keyword}[:\s]+(.+)', content, re.IGNORECASE)
                if matches:
                    result["indicators"]["has_plans"].extend([m.strip() for m in matches[:3]])
                    if result["recommendation"] == "REVIEW_NEEDED":
                        result["recommendation"] = "PLANNED_FEATURE"
            
            # Check for incomplete indicators
            incomplete_patterns = [
                r'not implemented',
                r'incomplete',
                r'stub',
                r'placeholder',
                r'coming soon',
                r'not yet',
            ]
            for pattern in incomplete_patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    result["indicators"]["has_incomplete"].append(pattern)
                    result["recommendation"] = "INCOMPLETE"
                    result["integration_needed"] = True
            
            # Check for stub functions
            if re.search(r'pass\s*$', content, re.MULTILINE):
                stub_count = len(re.findall(r'def\s+\w+.*:\s*pass', content))
                if stub_count > 0:
                    result["indicators"]["has_stubs"] = True
                    result["recommendation"] = "HAS_STUBS"
                    result["integration_needed"] = True
            
            # Parse AST for structure analysis
            try:
                tree = ast.parse(content, str(file_path))
                
                classes = [node for node in ast.walk(tree) if isinstance(node, ast.ClassDef)]
                functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
                
                result["indicators"]["class_count"] = len(classes)
                result["indicators"]["function_count"] = len(functions)
                
                # Check for docstrings (indicates intentional design)
                for node in functions + classes:
                    if ast.get_docstring(node):
                        result["indicators"]["has_docstrings"] = True
                        break
                
                # Check if functions are implemented
                implemented = 0
                for func in functions:
                    # Simple check - has more than just pass or docstring
                    func_body = [n for n in ast.walk(func) if isinstance(n, (ast.Return, ast.Assign, ast.Expr, ast.Call))]
                    if len(func_body) > 0:
                        implemented += 1
                
                result["indicators"]["implemented_functions"] = implemented
                
                # Determine implementation status
                if result["indicators"]["function_count"] > 0:
                    implementation_ratio = implemented / result["indicators"]["function_count"]
                    if implementation_ratio < 0.5:
                        result["implementation_status"] = "PARTIAL"
                        result["integration_needed"] = True
                    elif implementation_ratio == 1.0:
                        result["implementation_status"] = "COMPLETE"
                    else:
                        result["implementation_status"] = "MOSTLY_COMPLETE"
                
            except SyntaxError:
                result["implementation_status"] = "SYNTAX_ERROR"
            
        except Exception as e:
            result["error"] = str(e)
            result["recommendation"] = "ERROR_ANALYZING"
        
        return result
    
    def check_documentation_references(self, file_path: Path) -> List[str]:
        """Check if file is mentioned in documentation as planned/needed."""
        references = []
        module_name = str(file_path.stem)
        relative_path = str(file_path.relative_to(self.src_root))
        
        # Check documentation files
        doc_patterns = ["*.md", "*.rst", "*.txt"]
        
        for pattern in doc_patterns:
            for doc_file in self.project_root.rglob(pattern):
                if any(skip in str(doc_file) for skip in [".git", "__pycache__", "node_modules", "venv"]):
                    continue
                
                try:
                    with open(doc_file, "r", encoding="utf-8") as f:
                        content = f.read()
                        
                        # Check for file/module name
                        if module_name in content or relative_path in content:
                            # Check if it's mentioned as planned/needed
                            planned_keywords = [
                                "planned", "future", "upcoming", "roadmap",
                                "will implement", "to be implemented", "need",
                                "should have", "required", "necessary"
                            ]
                            context = content[max(0, content.find(module_name)-100):content.find(module_name)+200]
                            if any(kw in context.lower() for kw in planned_keywords):
                                references.append(f"Planned in {doc_file.relative_to(self.project_root)}")
                except Exception:
                    pass
        
        return references
    
    def analyze_files_from_list(self, analysis_file: str) -> Dict[str, Any]:
        """Analyze files from unnecessary_files_analysis.json."""
        print(f"üìã Loading analysis file: {analysis_file}")
        
        with open(analysis_file, "r", encoding="utf-8") as f:
            analysis_data = json.load(f)
        
        files_to_analyze = []
        
        # Collect all files from analysis
        for category in ["unused", "deprecated_directory", "deletion_markers", "duplicates"]:
            for file_info in analysis_data.get(category, []):
                file_path = Path(file_info["file_path"])
                if file_path.exists():
                    files_to_analyze.append(file_path)
        
        print(f"üîç Analyzing {len(files_to_analyze)} files for implementation status...\n")
        
        analysis_results = {
            "summary": {
                "total_files": len(files_to_analyze),
                "needs_implementation": 0,
                "planned_features": 0,
                "incomplete": 0,
                "has_stubs": 0,
                "complete_but_unused": 0,
                "needs_review": 0,
            },
            "needs_implementation": [],
            "planned_features": [],
            "incomplete": [],
            "has_stubs": [],
            "complete_but_unused": [],
            "needs_review": [],
        }
        
        for i, file_path in enumerate(files_to_analyze, 1):
            print(f"  [{i}/{len(files_to_analyze)}] Analyzing: {file_path.relative_to(self.src_root)}")
            
            result = self.analyze_file_content(file_path)
            
            # Check documentation references
            doc_refs = self.check_documentation_references(file_path)
            if doc_refs:
                result["documentation_references"] = doc_refs
                if "planned" in result["recommendation"].lower():
                    result["recommendation"] = "PLANNED_FEATURE"
            
            # Categorize result
            rec = result["recommendation"]
            if rec == "NEEDS_IMPLEMENTATION":
                analysis_results["needs_implementation"].append(result)
                analysis_results["summary"]["needs_implementation"] += 1
            elif rec == "PLANNED_FEATURE":
                analysis_results["planned_features"].append(result)
                analysis_results["summary"]["planned_features"] += 1
            elif rec == "INCOMPLETE":
                analysis_results["incomplete"].append(result)
                analysis_results["summary"]["incomplete"] += 1
            elif rec == "HAS_STUBS":
                analysis_results["has_stubs"].append(result)
                analysis_results["summary"]["has_stubs"] += 1
            elif result["implementation_status"] == "COMPLETE":
                analysis_results["complete_but_unused"].append(result)
                analysis_results["summary"]["complete_but_unused"] += 1
            else:
                analysis_results["needs_review"].append(result)
                analysis_results["summary"]["needs_review"] += 1
        
        return analysis_results


def main():
    """Main execution."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Analyze file implementation status")
    parser.add_argument(
        "--analysis-file",
        default="agent_workspaces/Agent-5/unnecessary_files_analysis.json",
        help="Path to unnecessary_files_analysis.json"
    )
    parser.add_argument(
        "--output",
        default="agent_workspaces/Agent-5/implementation_status_analysis.json",
        help="Output file path"
    )
    
    args = parser.parse_args()
    
    print("üîç FILE IMPLEMENTATION STATUS ANALYSIS")
    print("=" * 60)
    print("Checking if files need implementation/integration vs deletion\n")
    
    analyzer = FileImplementationAnalyzer()
    
    if not Path(args.analysis_file).exists():
        print(f"‚ùå Analysis file not found: {args.analysis_file}")
        return
    
    results = analyzer.analyze_files_from_list(args.analysis_file)
    
    print("\n" + "=" * 60)
    print("üìä IMPLEMENTATION STATUS SUMMARY")
    print("=" * 60)
    summary = results["summary"]
    print(f"Total Files Analyzed: {summary['total_files']}")
    print(f"\nüìù Needs Implementation: {summary['needs_implementation']}")
    print(f"üìã Planned Features: {summary['planned_features']}")
    print(f"‚ö†Ô∏è  Incomplete: {summary['incomplete']}")
    print(f"üîß Has Stubs: {summary['has_stubs']}")
    print(f"‚úÖ Complete but Unused: {summary['complete_but_unused']}")
    print(f"üîç Needs Review: {summary['needs_review']}")
    
    # Save results
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2)
    
    print(f"\n‚úÖ Results saved to: {output_path}")
    
    # Show top files needing implementation
    if results["needs_implementation"]:
        print("\n" + "=" * 60)
        print("üìù TOP FILES NEEDING IMPLEMENTATION")
        print("=" * 60)
        for result in results["needs_implementation"][:10]:
            print(f"\n{result['relative_path']}")
            if result["indicators"]["has_todos"]:
                print(f"  TODOs: {', '.join(result['indicators']['has_todos'][:2])}")
            if result["documentation_references"]:
                print(f"  Docs: {result['documentation_references'][0]}")
    
    print("\nüêù WE. ARE. SWARM. ‚ö°üî•")


if __name__ == "__main__":
    main()

