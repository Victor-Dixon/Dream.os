#!/usr/bin/env python3
"""
Functionality Verification Tool
===============================

Comprehensive verification system for consolidation safety.
Ensures 100% functionality preservation during 683‚Üí250 file consolidation.

Usage:
    python tools/functionality_verification.py --agent-id Agent-X --comprehensive
    python tools/functionality_verification.py --baseline
    python tools/functionality_verification.py --compare
"""

import sys
import json
import hashlib
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class FunctionalityVerifier:
    """Comprehensive functionality verification system."""

    def __init__(self):
        self.project_root = project_root
        self.baseline_file = self.project_root / "verification_baseline.json"
        self.results_dir = self.project_root / "verification_results"
        self.results_dir.mkdir(exist_ok=True)

    def generate_functionality_signature(self) -> Dict[str, Any]:
        """Generate comprehensive functionality signature."""

        signature = {
            "timestamp": datetime.now().isoformat(),
            "files": {},
            "functions": {},
            "classes": {},
            "imports": {},
            "tests": {},
            "apis": {},
            "configurations": {}
        }

        # Scan Python files
        for py_file in self.project_root.rglob("*.py"):
            if self._should_include_file(py_file):
                try:
                    content = py_file.read_text(encoding='utf-8')
                    file_hash = hashlib.md5(content.encode()).hexdigest()

                    signature["files"][str(py_file.relative_to(self.project_root))] = {
                        "hash": file_hash,
                        "size": len(content),
                        "functions": self._extract_functions(content),
                        "classes": self._extract_classes(content),
                        "imports": self._extract_imports(content)
                    }
                except Exception as e:
                    print(f"Warning: Could not process {py_file}: {e}")

        return signature

    def _should_include_file(self, file_path: Path) -> bool:
        """Determine if file should be included in verification."""
        # Exclude common non-functional files
        exclude_patterns = [
            "__pycache__",
            ".git",
            "node_modules",
            "*.pyc",
            ".pytest_cache",
            "verification_results",
            "runtime/backups"
        ]

        file_str = str(file_path)
        for pattern in exclude_patterns:
            if pattern in file_str:
                return False

        return file_path.suffix == ".py"

    def _extract_functions(self, content: str) -> List[str]:
        """Extract function definitions from Python code."""
        import re
        functions = []
        pattern = r'^def\s+(\w+)\s*\('
        for line in content.split('\n'):
            match = re.match(pattern, line.strip())
            if match:
                functions.append(match.group(1))
        return functions

    def _extract_classes(self, content: str) -> List[str]:
        """Extract class definitions from Python code."""
        import re
        classes = []
        pattern = r'^class\s+(\w+)'
        for line in content.split('\n'):
            match = re.match(pattern, line.strip())
            if match:
                classes.append(match.group(1))
        return classes

    def _extract_imports(self, content: str) -> List[str]:
        """Extract import statements from Python code."""
        import re
        imports = []
        patterns = [
            r'^import\s+([\w.]+)',
            r'^from\s+([\w.]+)\s+import'
        ]
        for line in content.split('\n'):
            for pattern in patterns:
                match = re.match(pattern, line.strip())
                if match:
                    imports.append(match.group(1))
        return list(set(imports))  # Remove duplicates

    def save_baseline(self, signature: Dict[str, Any]) -> None:
        """Save functionality baseline."""
        with open(self.baseline_file, 'w', encoding='utf-8') as f:
            json.dump(signature, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ Baseline saved to {self.baseline_file}")

    def load_baseline(self) -> Optional[Dict[str, Any]]:
        """Load functionality baseline."""
        if self.baseline_file.exists():
            with open(self.baseline_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

    def compare_with_baseline(self, current_signature: Dict[str, Any]) -> Dict[str, Any]:
        """Compare current state with baseline."""
        baseline = self.load_baseline()
        if not baseline:
            return {"error": "No baseline found. Run --baseline first."}

        comparison = {
            "timestamp": datetime.now().isoformat(),
            "baseline_timestamp": baseline["timestamp"],
            "files_changed": [],
            "functions_lost": [],
            "classes_lost": [],
            "new_functions": [],
            "new_classes": [],
            "import_changes": [],
            "risk_assessment": "LOW"
        }

        # Compare files
        baseline_files = set(baseline["files"].keys())
        current_files = set(current_signature["files"].keys())

        removed_files = baseline_files - current_files
        added_files = current_files - baseline_files

        for file in removed_files:
            comparison["files_changed"].append(f"REMOVED: {file}")

        for file in added_files:
            comparison["files_changed"].append(f"ADDED: {file}")

        # Compare functions and classes in common files
        common_files = baseline_files & current_files
        for file in common_files:
            baseline_info = baseline["files"][file]
            current_info = current_signature["files"][file]

            # Check functions
            baseline_funcs = set(baseline_info.get("functions", []))
            current_funcs = set(current_info.get("functions", []))
            lost_funcs = baseline_funcs - current_funcs
            new_funcs = current_funcs - baseline_funcs

            for func in lost_funcs:
                comparison["functions_lost"].append(f"{file}:{func}")
            for func in new_funcs:
                comparison["new_functions"].append(f"{file}:{func}")

            # Check classes
            baseline_classes = set(baseline_info.get("classes", []))
            current_classes = set(current_info.get("classes", []))
            lost_classes = baseline_classes - current_classes
            new_classes = current_classes - baseline_classes

            for cls in lost_classes:
                comparison["functions_lost"].append(f"{file}:{cls} (class)")
            for cls in new_classes:
                comparison["new_classes"].append(f"{file}:{cls} (class)")

        # Assess risk
        if comparison["functions_lost"] or len(removed_files) > 10:
            comparison["risk_assessment"] = "HIGH"
        elif len(comparison["files_changed"]) > 20:
            comparison["risk_assessment"] = "MEDIUM"
        else:
            comparison["risk_assessment"] = "LOW"

        return comparison

    def run_agent_specific_verification(self, agent_id: str) -> Dict[str, Any]:
        """Run agent-specific functionality verification."""
        results = {
            "agent_id": agent_id,
            "timestamp": datetime.now().isoformat(),
            "tests_run": [],
            "tests_passed": [],
            "tests_failed": [],
            "functionality_status": "UNKNOWN"
        }

        # Define agent-specific tests
        agent_tests = self._get_agent_tests(agent_id)

        for test_name, test_command in agent_tests.items():
            try:
                result = subprocess.run(
                    test_command,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=300  # 5 minute timeout
                )

                results["tests_run"].append(test_name)

                if result.returncode == 0:
                    results["tests_passed"].append(test_name)
                else:
                    results["tests_failed"].append({
                        "test": test_name,
                        "return_code": result.returncode,
                        "stdout": result.stdout[-500:],  # Last 500 chars
                        "stderr": result.stderr[-500:]   # Last 500 chars
                    })

            except subprocess.TimeoutExpired:
                results["tests_failed"].append({
                    "test": test_name,
                    "error": "TIMEOUT",
                    "timeout_seconds": 300
                })
            except Exception as e:
                results["tests_failed"].append({
                    "test": test_name,
                    "error": str(e)
                })

        # Determine overall status
        if not results["tests_run"]:
            results["functionality_status"] = "NO_TESTS"
        elif not results["tests_failed"]:
            results["functionality_status"] = "FULLY_FUNCTIONAL"
        elif len(results["tests_failed"]) / len(results["tests_run"]) < 0.1:
            results["functionality_status"] = "MINOR_ISSUES"
        else:
            results["functionality_status"] = "SIGNIFICANT_ISSUES"

        return results

    def _get_agent_tests(self, agent_id: str) -> Dict[str, str]:
        """Get agent-specific test commands."""
        base_tests = {
            "import_test": f"python -c \"import sys; sys.path.insert(0, '.'); from src.services.* import *; print('Imports OK')\"",
            "basic_functionality": "python -c \"print('Basic Python OK')\""
        }

        agent_specific_tests = {
            "Agent-1": {
                "integration_test": "python -m pytest tests/integration/ -v --tb=short",
                "api_test": "python -c \"from src.services.messaging_cli import *; print('API OK')\""
            },
            "Agent-2": {
                "architecture_test": "python -c \"from src.core.constants.fsm import *; print('Architecture OK')\"",
                "solid_test": "python -m pytest tests/test_solid_principles.py -v"
            },
            "Agent-3": {
                "infrastructure_test": "python -c \"from src.core.deployment import *; print('Infrastructure OK')\"",
                "performance_test": "python -m pytest tests/performance/ -v --tb=short"
            },
            "Agent-4": {
                "quality_test": "python -m pytest tests/ -k 'smoke' -v",
                "consolidation_test": "python -c \"from src.core.unified_config import *; print('Config OK')\""
            },
            "Agent-6": {
                "messaging_test": "python -m src.services.messaging_cli --check-status",
                "communication_test": "python -c \"from src.services.messaging_pyautogui import *; print('Messaging OK')\""
            },
            "Agent-7": {
                "web_test": "python -c \"from src.web.frontend import *; print('Web OK')\"",
                "frontend_test": "python -c \"print('Frontend components accessible')\""
            },
            "Agent-8": {
                "operations_test": "python -c \"from src.services.contract_service import *; print('Operations OK')\"",
                "workflow_test": "python -c \"print('Workflows accessible')\""
            }
        }

        tests = base_tests.copy()
        if agent_id in agent_specific_tests:
            tests.update(agent_specific_tests[agent_id])

        return tests

    def generate_verification_report(self, comparison: Dict[str, Any],
                                   agent_results: List[Dict[str, Any]]) -> str:
        """Generate comprehensive verification report."""
        report = []
        report.append("# üîç CONSOLIDATION VERIFICATION REPORT")
        report.append(f"**Generated:** {datetime.now().isoformat()}")
        report.append(f"**Risk Assessment:** {comparison.get('risk_assessment', 'UNKNOWN')}")
        report.append("")

        # Summary
        report.append("## üìä SUMMARY")
        report.append(f"- Files Changed: {len(comparison.get('files_changed', []))}")
        report.append(f"- Functions Lost: {len(comparison.get('functions_lost', []))}")
        report.append(f"- New Functions: {len(comparison.get('new_functions', []))}")
        report.append(f"- Agents Verified: {len(agent_results)}")
        report.append("")

        # Agent Status
        report.append("## üë• AGENT VERIFICATION STATUS")
        for agent_result in agent_results:
            status = agent_result.get('functionality_status', 'UNKNOWN')
            status_icon = {
                'FULLY_FUNCTIONAL': '‚úÖ',
                'MINOR_ISSUES': '‚ö†Ô∏è',
                'SIGNIFICANT_ISSUES': '‚ùå',
                'NO_TESTS': '‚ùì'
            }.get(status, '‚ùì')

            passed = len(agent_result.get('tests_passed', []))
            total = len(agent_result.get('tests_run', []))
            report.append(f"- {status_icon} **{agent_result['agent_id']}**: {passed}/{total} tests passed")
        report.append("")

        # Detailed Changes
        if comparison.get('functions_lost'):
            report.append("## ‚ö†Ô∏è FUNCTIONS/CLASSES LOST")
            for item in comparison['functions_lost'][:20]:  # Show first 20
                report.append(f"- ‚ùå {item}")
            if len(comparison['functions_lost']) > 20:
                report.append(f"- ... and {len(comparison['functions_lost']) - 20} more")
            report.append("")

        if comparison.get('files_changed'):
            report.append("## üìÅ FILES CHANGED")
            for change in comparison['files_changed'][:20]:  # Show first 20
                report.append(f"- üìÑ {change}")
            if len(comparison['files_changed']) > 20:
                report.append(f"- ... and {len(comparison['files_changed']) - 20} more")
            report.append("")

        # Recommendations
        report.append("## üéØ RECOMMENDATIONS")
        if comparison.get('functions_lost'):
            report.append("‚ùå **IMMEDIATE ACTION REQUIRED:** Functions/classes lost during consolidation")
            report.append("   - Review consolidation approach")
            report.append("   - Consider selective rollback")
        elif comparison.get('risk_assessment') == 'HIGH':
            report.append("‚ö†Ô∏è **HIGH RISK:** Significant changes detected")
            report.append("   - Conduct thorough manual testing")
            report.append("   - Prepare rollback procedures")
        elif comparison.get('risk_assessment') == 'MEDIUM':
            report.append("üü° **MEDIUM RISK:** Moderate changes detected")
            report.append("   - Continue with enhanced monitoring")
            report.append("   - Complete agent verification")
        else:
            report.append("‚úÖ **LOW RISK:** Minimal changes detected")
            report.append("   - Proceed with consolidation")
            report.append("   - Maintain monitoring")

        return "\n".join(report)


def main():
    """Main verification function."""
    import argparse

    parser = argparse.ArgumentParser(description="Functionality Verification Tool")
    parser.add_argument("--baseline", action="store_true", help="Generate functionality baseline")
    parser.add_argument("--compare", action="store_true", help="Compare with baseline")
    parser.add_argument("--agent-id", help="Run agent-specific verification")
    parser.add_argument("--comprehensive", action="store_true", help="Run comprehensive verification")
    parser.add_argument("--report", action="store_true", help="Generate verification report")

    args = parser.parse_args()

    verifier = FunctionalityVerifier()

    if args.baseline:
        print("üîç Generating functionality baseline...")
        signature = verifier.generate_functionality_signature()
        verifier.save_baseline(signature)
        print("‚úÖ Baseline generated successfully")

    elif args.agent_id:
        print(f"üîç Running verification for {args.agent_id}...")
        results = verifier.run_agent_specific_verification(args.agent_id)

        print(f"üìä {args.agent_id} Verification Results:")
        print(f"   Status: {results['functionality_status']}")
        print(f"   Tests Run: {len(results['tests_run'])}")
        print(f"   Tests Passed: {len(results['tests_passed'])}")
        print(f"   Tests Failed: {len(results['tests_failed'])}")

        if results['tests_failed']:
            print("   Failed Tests:")
            for failure in results['tests_failed']:
                print(f"     - {failure['test']}: {failure.get('error', 'FAILED')}")

    elif args.comprehensive:
        print("üîç Running comprehensive verification...")
        current_signature = verifier.generate_functionality_signature()
        comparison = verifier.compare_with_baseline(current_signature)

        # Run agent verifications
        agent_results = []
        for agent_id in ["Agent-1", "Agent-2", "Agent-3", "Agent-4", "Agent-6", "Agent-7", "Agent-8"]:
            print(f"Verifying {agent_id}...")
            result = verifier.run_agent_specific_verification(agent_id)
            agent_results.append(result)

        # Generate report
        report = verifier.generate_verification_report(comparison, agent_results)

        # Save report
        report_file = verifier.results_dir / f"verification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)

        print(f"‚úÖ Comprehensive verification complete")
        print(f"üìÑ Report saved to: {report_file}")

        # Print summary
        print("\nüìä SUMMARY:")
        print(f"   Risk Assessment: {comparison.get('risk_assessment', 'UNKNOWN')}")
        print(f"   Functions Lost: {len(comparison.get('functions_lost', []))}")
        print(f"   Files Changed: {len(comparison.get('files_changed', []))}")
        print(f"   Agents Verified: {len(agent_results)}")

        functional_agents = sum(1 for r in agent_results if r.get('functionality_status') == 'FULLY_FUNCTIONAL')
        print(f"   Fully Functional: {functional_agents}/{len(agent_results)}")

    else:
        print("Usage:")
        print("  python tools/functionality_verification.py --baseline")
        print("  python tools/functionality_verification.py --compare")
        print("  python tools/functionality_verification.py --agent-id Agent-X")
        print("  python tools/functionality_verification.py --comprehensive")


if __name__ == "__main__":
    main()
