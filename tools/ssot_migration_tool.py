#!/usr/bin/env python3
"""
SSOT Migration Tool - Automated Consolidation
==============================================

Automated tool to apply SSOT base classes to codebase.

<!-- SSOT Domain: migration -->

Features:
- Automated import consolidation
- Logger standardization
- Error handling unification
- Batch migration processing
- Migration verification

V2 Compliant: Automated SSOT adoption
Author: Agent-8 (SSOT & System Integration)
Date: 2026-01-12
"""

import argparse
import logging
import re
from pathlib import Path
from typing import List, Dict, Any, Set, Optional
from dataclasses import dataclass, field

# Add src to path for SSOT imports
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# SSOT imports
from src.core.base.import_standardization import ImportManager
from src.core.base.service_base import BaseService
from src.core.base.error_handling import ErrorHandler


@dataclass
class MigrationResult:
    """Result of a migration operation."""
    file_path: Path
    success: bool
    changes_made: List[str] = field(default_factory=list)
    errors: List[str] = field(default_factory=list)


class SSOTMigrationTool(BaseService):
    """
    Automated SSOT migration tool.

    Applies standardized patterns across the codebase to eliminate duplication.
    """

    def __init__(self):
        """Initialize migration tool."""
        super().__init__("ssot_migration_tool")
        self.import_manager = ImportManager()
        self.migration_patterns = self._load_migration_patterns()

    def _load_migration_patterns(self) -> Dict[str, Dict[str, Any]]:
        """Load migration patterns for different consolidation types."""
        return {
            "import_consolidation": {
                "pattern": r'from typing import ([^\n]+)',
                "replacement_func": self._consolidate_typing_imports,
                "description": "Consolidate multiple typing imports"
            },
            "logger_standardization": {
                "pattern": r'logger = logging\.getLogger\(__name__\)',
                "replacement": "# SSOT Logger - standardized through base classes\nlogger = logging.getLogger(__name__)",
                "description": "Standardize logger setup with SSOT comment"
            },
            "error_handler_import": {
                "pattern": r'import logging',
                "replacement": 'import logging\n# SSOT Error Handling\nimport sys\nsys.path.append(str(Path(__file__).parent.parent / "src"))\nfrom src.core.base.error_handling import ErrorHandler',
                "description": "Add SSOT error handling imports"
            }
        }

    def _consolidate_typing_imports(self, match: re.Match) -> str:
        """Consolidate typing imports using SSOT patterns."""
        imports_str = match.group(1)

        # Parse imports, removing duplicates
        imports = set()
        for imp in imports_str.split(','):
            imp = imp.strip()
            if imp:
                imports.add(imp)

        # Sort for consistency
        sorted_imports = sorted(imports)

        # Create consolidated import
        newline = '\n'
        consolidated = f"from src.core.base.import_standardization import ({newline}    {f',{newline}    '.join(sorted_imports)}{newline})"

        return consolidated

    def validate_config(self) -> bool:
        """Validate migration tool configuration."""
        required_paths = [
            Path("src/core/base/service_base.py"),
            Path("src/core/base/import_standardization.py"),
            Path("src/core/base/error_handling.py")
        ]

        for path in required_paths:
            if not path.exists():
                self.logger.error(f"Required SSOT file not found: {path}")
                return False

        return True

    async def start(self) -> bool:
        """Start migration tool."""
        self.logger.info("ðŸš€ SSOT Migration Tool starting...")
        return True

    async def stop(self) -> bool:
        """Stop migration tool."""
        self.logger.info("ðŸ‘‹ SSOT Migration Tool stopping...")
        return True

    def health_check(self) -> Dict[str, Any]:
        """Perform health check."""
        return {
            "status": "healthy",
            "patterns_loaded": len(self.migration_patterns),
            "ssot_files_present": self.validate_config()
        }

    def migrate_file(self, file_path: Path, dry_run: bool = True) -> MigrationResult:
        """
        Migrate a single file to use SSOT patterns.

        Args:
            file_path: Path to file to migrate
            dry_run: If True, don't modify file, just report changes

        Returns:
            MigrationResult with details of changes
        """
        result = MigrationResult(file_path, False)

        try:
            # Read file content
            content = file_path.read_text(encoding='utf-8')

            # Apply migration patterns
            modified_content = content
            changes_made = []

            for pattern_name, pattern_config in self.migration_patterns.items():
                pattern = pattern_config["pattern"]
                replacement = pattern_config["replacement"]
                description = pattern_config["description"]

                # Apply pattern
                new_content = re.sub(pattern, replacement, modified_content, flags=re.MULTILINE)

                if new_content != modified_content:
                    changes_made.append(f"{description}: {pattern_name}")
                    modified_content = new_content

            # Add SSOT header if not present
            if "V2 Consolidated:" not in modified_content and "SSOT Migration:" not in modified_content:
                ssot_header = "\nV2 Consolidated: Uses SSOT base classes for standardized patterns\nSSOT Migration: Agent-8 (System Integration)\nDate: 2026-01-12\n"
                # Insert after existing author/docstring
                lines = modified_content.split('\n')
                insert_idx = 0
                for i, line in enumerate(lines):
                    if line.strip().startswith('"""') and '"""' in line:
                        insert_idx = i + 1
                        break
                    elif line.strip().startswith('Author:') or line.strip().startswith('Created:'):
                        insert_idx = i + 1
                        break

                lines.insert(insert_idx, ssot_header)
                modified_content = '\n'.join(lines)
                changes_made.append("Added SSOT header")

            # Write back if not dry run
            if not dry_run and changes_made:
                file_path.write_text(modified_content, encoding='utf-8')
                result.success = True
            elif dry_run:
                result.success = True  # Dry run always "succeeds"

            result.changes_made = changes_made

        except Exception as e:
            result.errors.append(f"Migration failed: {str(e)}")
            self.logger.error(f"Failed to migrate {file_path}: {e}")

        return result

    def migrate_batch(self, file_paths: List[Path], dry_run: bool = True) -> List[MigrationResult]:
        """
        Migrate a batch of files.

        Args:
            file_paths: List of files to migrate
            dry_run: If True, don't modify files

        Returns:
            List of migration results
        """
        results = []

        for file_path in file_paths:
            self.logger.info(f"{'[DRY RUN] ' if dry_run else ''}Migrating {file_path}")
            result = self.migrate_file(file_path, dry_run)
            results.append(result)

            if result.success and result.changes_made:
                self.logger.info(f"âœ… Migrated {file_path}: {', '.join(result.changes_made)}")
            elif result.errors:
                self.logger.error(f"âŒ Failed {file_path}: {', '.join(result.errors)}")

        return results

    def find_migration_candidates(self, root_path: Path) -> List[Path]:
        """
        Find files that are candidates for SSOT migration.

        Args:
            root_path: Root directory to search

        Returns:
            List of file paths that need migration
        """
        candidates = []

        # Search for Python files
        for py_file in root_path.rglob("*.py"):
            if py_file.is_file():
                try:
                    content = py_file.read_text(encoding='utf-8')

                    # Check for migration indicators
                    indicators = [
                        'logger = logging.getLogger(__name__)',  # Logger pattern
                        'from typing import',  # Typing imports
                        'import logging',  # Logging imports
                    ]

                    if any(indicator in content for indicator in indicators):
                        # Skip already migrated files
                        if "SSOT Migration:" in content:
                            continue

                        candidates.append(py_file)

                except Exception as e:
                    self.logger.warning(f"Could not read {py_file}: {e}")

        return candidates


def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(description="SSOT Migration Tool")
    parser.add_argument("--action", choices=["migrate", "find", "dry-run"], required=True,
                       help="Action to perform")
    parser.add_argument("--root", type=Path, default=Path("src"),
                       help="Root directory to process")
    parser.add_argument("--files", nargs="*", type=Path,
                       help="Specific files to migrate")
    parser.add_argument("--output", type=Path,
                       help="Output file for results")

    args = parser.parse_args()

    # Initialize tool
    tool = SSOTMigrationTool()

    if not tool.validate_config():
        print("âŒ SSOT base files not found. Please ensure SSOT implementation is complete.")
        return 1

    if args.action == "find":
        # Find migration candidates
        candidates = tool.find_migration_candidates(args.root)
        print(f"Found {len(candidates)} migration candidates:")
        for candidate in candidates[:20]:  # Show first 20
            print(f"  {candidate}")
        if len(candidates) > 20:
            print(f"  ... and {len(candidates) - 20} more")

        if args.output:
            with open(args.output, 'w') as f:
                for candidate in candidates:
                    f.write(f"{candidate}\n")

    elif args.action in ["migrate", "dry-run"]:
        # Determine files to process
        if args.files:
            files_to_process = args.files
        else:
            files_to_process = tool.find_migration_candidates(args.root)

        dry_run = args.action == "dry-run"

        print(f"{'[DRY RUN] ' if dry_run else ''}Processing {len(files_to_process)} files...")

        # Migrate files
        results = tool.migrate_batch(files_to_process, dry_run=dry_run)

        # Summary
        successful = sum(1 for r in results if r.success)
        total_changes = sum(len(r.changes_made) for r in results)
        errors = sum(len(r.errors) for r in results)

        print(f"\nMigration Summary:")
        print(f"  Files processed: {len(results)}")
        print(f"  Successful: {successful}")
        print(f"  Total changes: {total_changes}")
        print(f"  Errors: {errors}")

        if args.output:
            import json
            with open(args.output, 'w') as f:
                json.dump([{
                    'file': str(r.file_path),
                    'success': r.success,
                    'changes': r.changes_made,
                    'errors': r.errors
                } for r in results], f, indent=2)


if __name__ == "__main__":
    exit(main())