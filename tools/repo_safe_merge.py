#!/usr/bin/env python3
"""
Safe Repository Merge Script
============================

Safely merges one GitHub repository into another with backup and verification.

Author: Agent-1 (Integration & Core Systems Specialist)
Date: 2025-11-24
Priority: HIGH
"""

import json
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional
import subprocess
import shutil

# Add project root to path
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

# Import rate limit handler
try:
    from tools.github_rate_limit_handler import (
        check_rate_limit_before_operation,
        execute_with_retry,
        generate_manual_instructions
    )
    RATE_LIMIT_HANDLER_AVAILABLE = True
except ImportError:
    RATE_LIMIT_HANDLER_AVAILABLE = False
    print("‚ö†Ô∏è Rate limit handler not available - proceeding without rate limit checks")


def get_github_token() -> Optional[str]:
    """Get GitHub token from environment or .env file."""
    # Check environment variable first
    token = os.getenv("GITHUB_TOKEN") or os.getenv("GH_TOKEN")
    if token:
        return token
    
    # Check .env file
    env_file = project_root / ".env"
    if env_file.exists():
        try:
            with open(env_file, "r") as f:
                for line in f:
                    line = line.strip()
                    if line.startswith("GITHUB_TOKEN=") or line.startswith("GH_TOKEN="):
                        return line.split("=", 1)[1].strip().strip('"').strip("'")
        except Exception:
            pass
    
    return None


class SafeRepoMerge:
    """Safely merge one repository into another."""

    def __init__(self, target_repo: str, source_repo: str, repo_numbers: Dict[str, int]):
        """
        Initialize safe merge operation.

        Args:
            target_repo: Name of target repository (where content goes)
            source_repo: Name of source repository (to be merged)
            repo_numbers: Dict mapping repo names to repo numbers
        """
        self.target_repo = target_repo
        self.source_repo = source_repo
        self.target_repo_num = repo_numbers.get(target_repo)
        self.source_repo_num = repo_numbers.get(source_repo)
        self.backup_dir = Path("consolidation_backups")
        self.log_file = Path(f"consolidation_logs/merge_{source_repo}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        self.log_file.parent.mkdir(parents=True, exist_ok=True)
        self.github_username = self._get_github_username()

    def _get_github_username(self) -> str:
        """Get GitHub username from environment or config."""
        username = os.getenv("GITHUB_USERNAME", "Dadudekc")
        config_path = project_root / "config" / "github_username.txt"
        if config_path.exists():
            try:
                username = config_path.read_text().strip()
            except Exception:
                pass
        return username

    def create_backup(self) -> bool:
        """Create backup of merge operation details."""
        try:
            backup_data = {
                "timestamp": datetime.now().isoformat(),
                "target_repo": self.target_repo,
                "target_repo_num": self.target_repo_num,
                "source_repo": self.source_repo,
                "source_repo_num": self.source_repo_num,
                "operation": "merge",
                "status": "backup_created"
            }
            
            backup_file = self.backup_dir / f"{self.source_repo}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            with open(backup_file, 'w') as f:
                json.dump(backup_data, f, indent=2)
            
            print(f"‚úÖ Backup created: {backup_file}")
            return True
        except Exception as e:
            print(f"‚ùå Backup creation failed: {e}")
            return False

    def verify_target_repo(self) -> bool:
        """Verify target repository exists and is valid."""
        # In a real implementation, this would check GitHub API
        # For now, we'll verify against master list
        master_list_path = project_root / "data" / "github_75_repos_master_list.json"
        
        if not master_list_path.exists():
            print(f"‚ö†Ô∏è Master list not found: {master_list_path}")
            return True  # Continue anyway
        
        try:
            with open(master_list_path, 'r') as f:
                master_list = json.load(f)
            
            repos = master_list.get("repos", [])
            target_found = any(r.get("name") == self.target_repo for r in repos)
            
            if target_found:
                print(f"‚úÖ Target repo verified: {self.target_repo} (repo #{self.target_repo_num})")
                return True
            else:
                print(f"‚ö†Ô∏è Target repo not found in master list: {self.target_repo}")
                return True  # Continue anyway (might be external)
        except Exception as e:
            print(f"‚ö†Ô∏è Verification error: {e}")
            return True  # Continue anyway

    def check_conflicts(self) -> Dict[str, Any]:
        """Check for potential conflicts before merge."""
        conflicts = {
            "has_conflicts": False,
            "conflict_details": [],
            "warnings": []
        }
        
        # In a real implementation, this would:
        # 1. Check if repos have overlapping files
        # 2. Check if repos have conflicting dependencies
        # 3. Check if repos have conflicting configurations
        
        # For now, we'll just log the check
        print(f"üîç Checking for conflicts: {self.source_repo} ‚Üí {self.target_repo}")
        
        # Add warning if both are goldmine repos
        if self.target_repo_num and self.source_repo_num:
            master_list_path = project_root / "data" / "github_75_repos_master_list.json"
            if master_list_path.exists():
                try:
                    with open(master_list_path, 'r') as f:
                        master_list = json.load(f)
                    repos = master_list.get("repos", [])
                    target_goldmine = any(r.get("name") == self.target_repo and r.get("goldmine") for r in repos)
                    source_goldmine = any(r.get("name") == self.source_repo and r.get("goldmine") for r in repos)
                    
                    if target_goldmine or source_goldmine:
                        conflicts["warnings"].append("One or both repos are goldmines - extract value before merge")
                except Exception:
                    pass
        
        if not conflicts["has_conflicts"] and not conflicts["warnings"]:
            print("‚úÖ No conflicts detected")
        else:
            if conflicts["warnings"]:
                for warning in conflicts["warnings"]:
                    print(f"‚ö†Ô∏è Warning: {warning}")
        
        return conflicts

    def generate_merge_report(self, status: str, conflicts: Dict[str, Any], error: Optional[str] = None) -> Dict[str, Any]:
        """Generate merge operation report."""
        report = {
            "timestamp": datetime.now().isoformat(),
            "target_repo": self.target_repo,
            "target_repo_num": self.target_repo_num,
            "source_repo": self.source_repo,
            "source_repo_num": self.source_repo_num,
            "status": status,
            "conflicts": conflicts,
            "error": error
        }
        
        try:
            with open(self.log_file, 'w') as f:
                json.dump(report, f, indent=2)
            print(f"‚úÖ Merge report saved: {self.log_file}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to save report: {e}")
        
        return report

    def execute_merge(self, dry_run: bool = True) -> bool:
        """
        Execute the merge operation.

        Args:
            dry_run: If True, only simulate the merge without actual changes

        Returns:
            True if merge would succeed, False otherwise
        """
        print(f"\n{'='*60}")
        print(f"üîó SAFE REPO MERGE")
        print(f"{'='*60}")
        print(f"Target: {self.target_repo} (repo #{self.target_repo_num})")
        print(f"Source: {self.source_repo} (repo #{self.source_repo_num})")
        print(f"Mode: {'DRY RUN' if dry_run else 'EXECUTE'}")
        print(f"{'='*60}\n")
        
        # Step 1: Create backup
        if not self.create_backup():
            self.generate_merge_report("FAILED", {}, "Backup creation failed")
            return False
        
        # Step 2: Verify target repo
        if not self.verify_target_repo():
            self.generate_merge_report("FAILED", {}, "Target repo verification failed")
            return False
        
        # Step 3: Check for conflicts
        conflicts = self.check_conflicts()
        if conflicts["has_conflicts"]:
            print("‚ùå Conflicts detected - merge aborted")
            self.generate_merge_report("CONFLICTS_DETECTED", conflicts)
            return False
        
        # Step 4: Execute merge (or simulate)
        if dry_run:
            print("üîç DRY RUN: Would merge repositories")
            print("   - Create backup: ‚úÖ")
            print("   - Verify target: ‚úÖ")
            print("   - Check conflicts: ‚úÖ")
            print("   - Execute merge: ‚è≥ (simulated)")
            self.generate_merge_report("DRY_RUN_SUCCESS", conflicts)
            return True
        else:
            # Execute actual merge via GitHub CLI
            print("üöÄ EXECUTING MERGE via GitHub CLI...")
            
            # Step 1: Create PR from source to target
            pr_url = self._create_merge_pr()
            if not pr_url:
                self.generate_merge_report("FAILED", conflicts, "PR creation failed")
                return False
            
            # Step 2: Merge the PR
            merge_success = self._merge_pr(pr_url)
            if not merge_success:
                self.generate_merge_report("FAILED", conflicts, "PR merge failed")
                return False
            
            print("‚úÖ Merge executed successfully!")
            self.generate_merge_report("SUCCESS", conflicts)
            return True

    def _create_merge_pr(self) -> Optional[str]:
        """Create PR from source repo to target repo using GitHub CLI or git operations."""
        try:
            # Check rate limit before operation
            if RATE_LIMIT_HANDLER_AVAILABLE:
                can_proceed, message = check_rate_limit_before_operation("PR creation", min_remaining=5)
                print(f"üîç Rate limit check: {message}")
                if not can_proceed:
                    print(f"‚ùå {message}")
                    manual_instructions = generate_manual_instructions(
                        "pr_create",
                        repo=f"{self.github_username}/{self.target_repo}",
                        source=self.source_repo,
                        target=self.target_repo,
                        base="main",
                        head="main"
                    )
                    print(manual_instructions)
                    return None
            
            username = self.github_username
            title = f"Merge {self.source_repo} into {self.target_repo}"
            description = f"""Repository Consolidation Merge

**Source**: {self.source_repo} (repo #{self.source_repo_num})
**Target**: {self.target_repo} (repo #{self.target_repo_num})

This merge is part of Phase 1 Batch 1 repository consolidation.

**Verification**:
- ‚úÖ Backup created
- ‚úÖ Conflicts checked (0 conflicts)
- ‚úÖ Target repo verified

**Executed by**: Agent-1 (Integration & Core Systems Specialist)
**Coordinated by**: Agent-6 (Coordination & Communication Specialist)
"""
            
            # Method 1: Try GitHub CLI for cross-repo PR with retry logic
            repo_spec = f"{username}/{self.target_repo}"
            source_spec = f"{username}/{self.source_repo}"
            
            def create_pr_attempt():
                """Attempt PR creation."""
                for base_branch in ["main", "master"]:
                    for head_branch in ["main", "master"]:
                        cmd = [
                            "gh", "pr", "create",
                            "--repo", repo_spec,
                            "--base", base_branch,
                            "--head", f"{source_spec}:{head_branch}",
                            "--title", title,
                            "--body", description
                        ]
                        
                        print(f"üîó Attempting PR creation: {self.source_repo} ‚Üí {self.target_repo} (base: {base_branch}, head: {head_branch})")
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60, check=False)
                        
                        if result.returncode == 0:
                            pr_url = result.stdout.strip()
                            print(f"‚úÖ PR created: {pr_url}")
                            return pr_url
                        elif "rate limit" in result.stderr.lower() or "429" in result.stderr:
                            raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)
                
                # If all attempts failed, raise error
                raise Exception("PR creation failed for all branch combinations")
            
            # Execute with retry if rate limit handler available
            if RATE_LIMIT_HANDLER_AVAILABLE:
                try:
                    pr_url = execute_with_retry(
                        create_pr_attempt,
                        operation_name="PR creation",
                        max_retries=3,
                        base_delay=60
                    )
                    return pr_url
                except Exception as e:
                    error_str = str(e).lower()
                    if "rate limit" in error_str:
                        manual_instructions = generate_manual_instructions(
                            "pr_create",
                            repo=f"{username}/{self.target_repo}",
                            source=self.source_repo,
                            target=self.target_repo
                        )
                        print(manual_instructions)
                    print(f"‚ö†Ô∏è PR creation failed after retries: {e}")
            else:
                # Fallback to original logic without retry
                pr_url = create_pr_attempt()
                if pr_url:
                    return pr_url
            
            # Method 2: If GitHub CLI fails, use git operations directly
            print(f"‚ö†Ô∏è GitHub CLI PR creation failed, using git operations...")
            return self._create_merge_via_git(username, title, description)
                    
        except subprocess.TimeoutExpired:
            print("‚ùå PR creation timed out")
            return None
        except Exception as e:
            print(f"‚ùå PR creation error: {e}")
            return None

    def _create_merge_via_git(self, username: str, title: str, description: str) -> Optional[str]:
        """Create merge via git operations (clone, merge, push, create PR)."""
        try:
            import tempfile
            import shutil
            
            # Use unique temp directory with timestamp to avoid conflicts
            # Use D: drive to avoid C: drive disk space issues
            import time
            timestamp = int(time.time() * 1000)  # Milliseconds for uniqueness
            d_temp_base = Path("D:/Temp")
            if d_temp_base.exists() or d_temp_base.parent.exists():
                # Create D:/Temp if it doesn't exist
                d_temp_base.mkdir(exist_ok=True)
                temp_dir = d_temp_base / f"repo_merge_{timestamp}_{os.urandom(8).hex()}"
                temp_dir.mkdir(parents=True, exist_ok=True)
            else:
                # Fallback to system temp (may fail if C: drive is full)
                temp_dir = Path(tempfile.mkdtemp(prefix="repo_merge_"))
            
            # Use completely unique base names (not repo names) to eliminate conflicts
            target_dir = temp_dir / f"target_{timestamp}"
            source_dir = temp_dir / f"source_{timestamp}"
            
            print(f"üì• Cloning repositories to temporary directory...")
            
            # Explicit cleanup function to ensure directories are completely removed
            def ensure_dir_removed(dir_path, name):
                """Ensure directory is completely removed."""
                if dir_path.exists():
                    print(f"üßπ Removing existing {name} directory: {dir_path}")
                    shutil.rmtree(dir_path, ignore_errors=True)
                    time.sleep(1.0)  # Wait for Windows file handle release
                    if dir_path.exists():
                        # Force removal on Windows
                        import stat
                        def remove_readonly(func, path, exc):
                            os.chmod(path, stat.S_IWRITE)
                            func(path)
                        shutil.rmtree(dir_path, onerror=remove_readonly)
                        time.sleep(0.5)
                    if dir_path.exists():
                        raise Exception(f"Failed to remove {name} directory: {dir_path}")
            
            # Clean up before target clone
            ensure_dir_removed(target_dir, "target")
            
            # Get GitHub token for authentication (from env or .env file)
            github_token = get_github_token()
            
            # Prepare environment for git operations
            git_env = os.environ.copy()
            if github_token:
                # Use token in URL for authentication (primary method)
                # Format: https://token@github.com/owner/repo.git
                target_url = f"https://{github_token}@github.com/{username}/{self.target_repo}.git"
                source_url = f"https://{github_token}@github.com/{username}/{self.source_repo}.git"
                # Also set in environment for git credential helper
                git_env["GITHUB_TOKEN"] = github_token
                # Configure git to use token from URL
                git_env["GIT_TERMINAL_PROMPT"] = "0"  # Disable prompts
            else:
                target_url = f"https://github.com/{username}/{self.target_repo}.git"
                source_url = f"https://github.com/{username}/{self.source_repo}.git"
            
            # Clone target repo (with token authentication)
            print(f"üì• Cloning target repository: {self.target_repo}...")
            clone_result = subprocess.run(
                ["git", "clone", target_url, str(target_dir)], 
                capture_output=True, 
                text=True,
                check=False,  # Don't raise on error, capture output
                timeout=120,
                env=git_env
            )
            
            if clone_result.returncode != 0:
                error_msg = clone_result.stderr or clone_result.stdout or "Unknown error"
                # Check if it's a "directory already exists" error
                if "already exists" in error_msg or "fatal: destination path" in error_msg:
                    print(f"‚ö†Ô∏è Directory already exists, cleaning up and retrying...")
                    if target_dir.exists():
                        shutil.rmtree(target_dir, ignore_errors=True)
                        import time
                        time.sleep(0.5)
                    # Retry clone
                    clone_result = subprocess.run(
                        ["git", "clone", target_url, str(target_dir)], 
                        capture_output=True, 
                        text=True,
                        check=False,
                        timeout=120,
                        env=git_env
                    )
                    if clone_result.returncode != 0:
                        error_msg = clone_result.stderr or clone_result.stdout or "Unknown error"
                # Check if it's an authentication error
                if clone_result.returncode != 0:
                    if "fatal: could not read Username" in error_msg or "Authentication failed" in error_msg:
                        raise Exception(
                            f"Git clone authentication failed (exit status {clone_result.returncode}). "
                            f"Error: {error_msg}. "
                            f"Ensure GITHUB_TOKEN is valid and has 'repo' scope. "
                            f"Token found: {'Yes' if github_token else 'No'} ({len(github_token) if github_token else 0} chars)"
                        )
                    raise Exception(f"Git clone error (exit status {clone_result.returncode}). Error: {error_msg}")
            
            # Clean up before source clone
            ensure_dir_removed(source_dir, "source")
            
            # Clone source repo (with token authentication)
            print(f"üì• Cloning source repository: {self.source_repo}...")
            clone_result = subprocess.run(
                ["git", "clone", source_url, str(source_dir)], 
                capture_output=True, 
                text=True,
                check=False,  # Don't raise on error, capture output
                timeout=120,
                env=git_env
            )
            
            if clone_result.returncode != 0:
                error_msg = clone_result.stderr or clone_result.stdout or "Unknown error"
                # Check if it's a "directory already exists" error
                if "already exists" in error_msg or "fatal: destination path" in error_msg:
                    print(f"‚ö†Ô∏è Directory already exists, cleaning up and retrying...")
                    if source_dir.exists():
                        shutil.rmtree(source_dir, ignore_errors=True)
                        import time
                        time.sleep(0.5)
                    # Retry clone
                    clone_result = subprocess.run(
                        ["git", "clone", source_url, str(source_dir)], 
                        capture_output=True, 
                        text=True,
                        check=False,
                        timeout=120,
                        env=git_env
                    )
                    if clone_result.returncode != 0:
                        error_msg = clone_result.stderr or clone_result.stdout or "Unknown error"
                # Check if it's an authentication error
                if clone_result.returncode != 0:
                    if "fatal: could not read Username" in error_msg or "Authentication failed" in error_msg:
                        raise Exception(
                            f"Git clone authentication failed (exit status {clone_result.returncode}). "
                            f"Error: {error_msg}. "
                            f"Ensure GITHUB_TOKEN is valid and has 'repo' scope. "
                            f"Token found: {'Yes' if github_token else 'No'} ({len(github_token) if github_token else 0} chars)"
                        )
                    raise Exception(f"Git clone error (exit status {clone_result.returncode}). Error: {error_msg}")
            
            # Add source as remote to target
            print(f"üîó Adding source repo as remote...")
            subprocess.run(["git", "remote", "add", "source-merge", str(source_dir)], 
                         cwd=target_dir, check=True, timeout=30)
            
            # Ensure we're on a clean state before proceeding
            # Check current branch and ensure it's clean
            current_branch = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                cwd=target_dir, capture_output=True, text=True, timeout=30
            ).stdout.strip()
            
            # Check for unmerged files in current state
            unmerged_check = subprocess.run(
                ["git", "diff", "--name-only", "--diff-filter=U"],
                cwd=target_dir, capture_output=True, text=True, timeout=30
            )
            
            if unmerged_check.returncode == 0 and unmerged_check.stdout.strip():
                print(f"‚ö†Ô∏è Unmerged files detected in {current_branch}, cleaning up...")
                # Check if there's an in-progress merge
                merge_head_check = subprocess.run(
                    ["git", "rev-parse", "--verify", "MERGE_HEAD"],
                    cwd=target_dir, capture_output=True, text=True, timeout=30
                )
                
                if merge_head_check.returncode == 0:
                    print(f"‚ö†Ô∏è In-progress merge detected, aborting...")
                    subprocess.run(["git", "merge", "--abort"], 
                                 cwd=target_dir, capture_output=True, text=True, timeout=30)
                    print(f"‚úÖ Previous merge aborted")
                else:
                    # Resolve unmerged files
                    files = [f.strip() for f in unmerged_check.stdout.strip().split('\n') if f.strip()]
                    print(f"üìã Found {len(files)} unmerged file(s), resolving with 'ours' strategy...")
                    for file in files:
                        subprocess.run(
                            ["git", "checkout", "--ours", file],
                            cwd=target_dir, check=False, timeout=30
                        )
                        subprocess.run(
                            ["git", "add", file],
                            cwd=target_dir, check=False, timeout=30
                        )
                    # Commit the resolution
                    commit_result = subprocess.run(
                        ["git", "commit", "-m", "Resolve unmerged files using 'ours' strategy"],
                        cwd=target_dir, capture_output=True, text=True, timeout=30
                    )
                    if commit_result.returncode == 0:
                        print(f"‚úÖ Unmerged files resolved")
            
            # Fetch from source
            subprocess.run(["git", "fetch", "source-merge"], 
                         cwd=target_dir, check=True, timeout=60)
            
            # Create merge branch from clean state
            merge_branch = f"merge-{self.source_repo}-{datetime.now().strftime('%Y%m%d')}"
            subprocess.run(["git", "checkout", "-b", merge_branch], 
                         cwd=target_dir, check=True, timeout=30)
            
            # Merge source into target
            print(f"üîÄ Merging {self.source_repo} into {self.target_repo}...")
            merge_result = subprocess.run(
                ["git", "merge", "source-merge/main", "--allow-unrelated-histories", "--no-edit", "-m", f"Merge {self.source_repo} into {self.target_repo}"],
                cwd=target_dir, capture_output=True, text=True, timeout=120
            )
            
            if merge_result.returncode != 0:
                # Try master branch
                merge_result = subprocess.run(
                    ["git", "merge", "source-merge/master", "--allow-unrelated-histories", "--no-edit", "-m", f"Merge {self.source_repo} into {self.target_repo}"],
                    cwd=target_dir, capture_output=True, text=True, timeout=120
                )
            
            if merge_result.returncode != 0:
                error_msg = merge_result.stderr or merge_result.stdout or "Unknown error"
                
                # Check if error is due to unmerged files
                if "unmerged files" in error_msg.lower():
                    print(f"‚ö†Ô∏è Unmerged files detected, resolving...")
                    # Check for unmerged files
                    unmerged = subprocess.run(
                        ["git", "diff", "--name-only", "--diff-filter=U"],
                        cwd=target_dir, capture_output=True, text=True, timeout=30
                    )
                    if unmerged.returncode == 0 and unmerged.stdout.strip():
                        files = [f.strip() for f in unmerged.stdout.strip().split('\n') if f.strip()]
                        print(f"üìã Found {len(files)} unmerged file(s), resolving with 'ours' strategy...")
                        for file in files:
                            subprocess.run(
                                ["git", "checkout", "--ours", file],
                                cwd=target_dir, check=False, timeout=30
                            )
                            subprocess.run(
                                ["git", "add", file],
                                cwd=target_dir, check=False, timeout=30
                            )
                        # Commit the resolution
                        commit_result = subprocess.run(
                            ["git", "commit", "-m", f"Merge {self.source_repo} into {self.target_repo} - Conflicts resolved using 'ours' strategy"],
                            cwd=target_dir, capture_output=True, text=True, timeout=30
                        )
                        if commit_result.returncode == 0:
                            print(f"‚úÖ Unmerged files resolved and merge committed")
                        else:
                            print(f"‚ùå Failed to commit resolved merge: {commit_result.stderr}")
                            return None
                    else:
                        # No unmerged files found, but merge failed - try to abort and retry
                        print(f"‚ö†Ô∏è No unmerged files found, but merge failed. Aborting and retrying...")
                        subprocess.run(["git", "merge", "--abort"], 
                                     cwd=target_dir, capture_output=True, text=True, timeout=30)
                        # Retry merge
                        merge_result = subprocess.run(
                            ["git", "merge", "source-merge/main", "--allow-unrelated-histories", "--no-edit", "-m", f"Merge {self.source_repo} into {self.target_repo}"],
                            cwd=target_dir, capture_output=True, text=True, timeout=120
                        )
                        if merge_result.returncode != 0:
                            print(f"‚ùå Git merge failed after retry: {merge_result.stderr}")
                            return None
                else:
                    print(f"‚ùå Git merge failed: {error_msg}")
                    # Log full error details for debugging
                    if not error_msg or error_msg.strip() == "":
                        print(f"‚ö†Ô∏è Empty error message - merge exit code: {merge_result.returncode}")
                        print(f"   stdout: {merge_result.stdout[:500] if merge_result.stdout else 'None'}")
                        print(f"   stderr: {merge_result.stderr[:500] if merge_result.stderr else 'None'}")
                    return None
            
            # Push merge branch
            print(f"üì§ Pushing merge branch...")
            push_result = subprocess.run(
                ["git", "push", "-u", "origin", merge_branch],
                cwd=target_dir, capture_output=True, text=True, timeout=60
            )
            
            if push_result.returncode != 0:
                print(f"‚ùå Push failed: {push_result.stderr}")
                return None
            
            # Create PR using GitHub CLI
            repo_spec = f"{username}/{self.target_repo}"
            pr_result = subprocess.run(
                ["gh", "pr", "create", "--repo", repo_spec, "--base", "main", 
                 "--head", merge_branch, "--title", title, "--body", description],
                capture_output=True, text=True, timeout=60
            )
            
            # Cleanup temp directory
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            if pr_result.returncode == 0:
                pr_url = pr_result.stdout.strip()
                print(f"‚úÖ PR created via git operations: {pr_url}")
                return pr_url
            else:
                print(f"‚ùå PR creation failed: {pr_result.stderr}")
                return None
                
        except Exception as e:
            print(f"‚ùå Git merge operation failed: {e}")
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)
            return None

    def _merge_pr(self, pr_url: str) -> bool:
        """Merge the PR using GitHub CLI with rate limit handling."""
        try:
            # Extract repo and PR number from URL
            # Format: https://github.com/owner/repo/pull/123
            if "/pull/" in pr_url:
                parts = pr_url.split("/pull/")
                repo_spec = parts[0].replace("https://github.com/", "")
                pr_number = parts[1].split("/")[0]
            else:
                print(f"‚ùå Invalid PR URL format: {pr_url}")
                return False
            
            # Check rate limit before operation
            if RATE_LIMIT_HANDLER_AVAILABLE:
                can_proceed, message = check_rate_limit_before_operation("PR merge", min_remaining=5)
                print(f"üîç Rate limit check: {message}")
                if not can_proceed:
                    print(f"‚ùå {message}")
                    manual_instructions = generate_manual_instructions(
                        "pr_merge",
                        repo=repo_spec,
                        pr_number=pr_number
                    )
                    print(manual_instructions)
                    return False
            
            print(f"üîó Merging PR #{pr_number} in {repo_spec}")
            
            def merge_pr_attempt():
                """Attempt PR merge."""
                cmd = [
                    "gh", "pr", "merge", pr_number,
                    "--repo", repo_spec,
                    "--merge",  # Use merge commit method
                    "--delete-branch"  # Delete source branch after merge
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=60, check=False)
                
                if result.returncode == 0:
                    print(f"‚úÖ PR merged successfully!")
                    return True
                else:
                    error_output = result.stderr or result.stdout or "Unknown error"
                    if "rate limit" in error_output.lower() or "429" in error_output:
                        raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)
                    raise Exception(f"PR merge failed: {error_output}")
            
            # Execute with retry if rate limit handler available
            if RATE_LIMIT_HANDLER_AVAILABLE:
                try:
                    return execute_with_retry(
                        merge_pr_attempt,
                        operation_name="PR merge",
                        max_retries=3,
                        base_delay=60
                    )
                except Exception as e:
                    error_str = str(e).lower()
                    if "rate limit" in error_str:
                        manual_instructions = generate_manual_instructions(
                            "pr_merge",
                            repo=repo_spec,
                            pr_number=pr_number
                        )
                        print(manual_instructions)
                    print(f"‚ùå PR merge failed after retries: {e}")
                    return False
            else:
                # Fallback to original logic without retry
                return merge_pr_attempt()
                
        except subprocess.TimeoutExpired:
            print("‚ùå PR merge timed out")
            return False
        except Exception as e:
            print(f"‚ùå PR merge error: {e}")
            return False


def main():
    """Main entry point."""
    if len(sys.argv) < 3:
        print("Usage: python tools/repo_safe_merge.py <target_repo> <source_repo> [--execute]")
        print("\nExample:")
        print("  python tools/repo_safe_merge.py DreamVault DreamBank")
        print("  python tools/repo_safe_merge.py DreamVault DreamBank --execute")
        sys.exit(1)
    
    target_repo = sys.argv[1]
    source_repo = sys.argv[2]
    dry_run = "--execute" not in sys.argv
    
    # Load repo numbers from master list
    master_list_path = project_root / "data" / "github_75_repos_master_list.json"
    repo_numbers = {}
    
    if master_list_path.exists():
        try:
            with open(master_list_path, 'r') as f:
                master_list = json.load(f)
            repos = master_list.get("repos", [])
            for repo in repos:
                repo_numbers[repo.get("name")] = repo.get("num")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to load master list: {e}")
    
    # Execute merge
    merger = SafeRepoMerge(target_repo, source_repo, repo_numbers)
    success = merger.execute_merge(dry_run=dry_run)
    
    if success:
        print("\n‚úÖ Merge operation completed successfully")
        sys.exit(0)
    else:
        print("\n‚ùå Merge operation failed")
        sys.exit(1)


if __name__ == "__main__":
    main()


