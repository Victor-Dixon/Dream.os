#!/usr/bin/env python3
"""
Improved Conversation Scraper with Aggressive Scrolling
======================================================

Designed to handle large numbers of conversations (1,300+) with better scrolling logic
and unified login utility.
"""

import sys
import os
import time
import json
from datetime import datetime

# Add the project root to the path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    import undetected_chromedriver as uc
    print("‚úÖ undetected-chromedriver available")
except ImportError:
    print("‚ùå undetected-chromedriver not available")
    sys.exit(1)

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException
from dreamscape.scrapers.login_utils import ensure_login_unified, create_login_components
from dreamscape.scrapers.cookie_manager import CookieManager
from dreamscape.scrapers.login_handler import LoginHandler
from dreamscape.scrapers.browser_manager import BrowserManager

class ImprovedConversationScraper:
    """Improved conversation scraper with aggressive scrolling."""
    
    def __init__(self, timeout: int = 30):
        self.timeout = timeout
    
    def get_conversation_list(self, driver) -> list:
        """Get list of all conversations with aggressive scrolling."""
        if not driver:
            print("‚ùå No driver provided")
            return []
        
        try:
            print("üìã Extracting conversation list with aggressive scrolling...")
            
            # Wait for page to load
            wait = WebDriverWait(driver, self.timeout)
            
            # Find the conversation sidebar
            sidebar_selectors = [
                "//div[contains(@class, 'bg-token-sidebar-surface-primary')]",
                "//div[contains(@class, 'sidebar')]",
                "//nav[contains(@class, 'sidebar')]",
                "//aside[contains(@class, 'sidebar')]",
                "//div[contains(@class, 'conversations')]",
                "//nav[contains(@class, 'conversations')]",
                "//div[contains(@class, 'flex-col') and contains(@class, 'overflow')]"
            ]
            
            sidebar = None
            for selector in sidebar_selectors:
                try:
                    sidebar = wait.until(EC.presence_of_element_located((By.XPATH, selector)))
                    print(f"‚úÖ Found sidebar using selector: {selector}")
                    break
                except TimeoutException:
                    continue
            
            if not sidebar:
                print("‚ùå Could not find conversation sidebar")
                return []
            
            # Wait for initial conversations to load
            print("‚è≥ Waiting for initial conversations to load...")
            time.sleep(5)
            
            # Aggressive scrolling to load all conversations
            print("üîÑ Starting aggressive scrolling to load all conversations...")
            self._aggressive_scroll(driver, sidebar)
            
            # Extract all conversations
            print("üìù Extracting conversation data...")
            conversations = self._extract_conversations(driver)
            
            print(f"‚úÖ Successfully extracted {len(conversations)} conversations!")
            return conversations
            
        except Exception as e:
            print(f"‚ùå Error extracting conversations: {e}")
            return []
    
    def _aggressive_scroll(self, driver, sidebar):
        """Aggressive scrolling to load all conversations."""
        try:
            # Get initial count
            initial_count = len(driver.find_elements(By.XPATH, "//a[contains(@href, '/c/')]"))
            print(f"üìä Initial conversation count: {initial_count}")
            
            # Very aggressive scrolling for large lists
            max_scrolls = 100  # Much higher limit
            no_change_count = 0
            max_no_change = 8  # More patience before stopping
            
            for i in range(max_scrolls):
                # Scroll to bottom
                driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", sidebar)
                time.sleep(2)  # Wait for loading
                
                # Check new count
                new_count = len(driver.find_elements(By.XPATH, "//a[contains(@href, '/c/')]"))
                
                # Progress indicator
                if (i + 1) % 5 == 0:
                    print(f"üìà Scroll {i+1}/{max_scrolls}: {new_count} conversations")
                
                # Check if we're still loading new conversations
                if new_count <= initial_count:
                    no_change_count += 1
                    
                    # Try more aggressive scrolling after a few attempts
                    if no_change_count >= 3:
                        print("üöÄ Trying more aggressive scrolling...")
                        for j in range(5):  # Multiple quick scrolls
                            driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", sidebar)
                            time.sleep(0.5)
                        
                        # Check again
                        new_count = len(driver.find_elements(By.XPATH, "//a[contains(@href, '/c/')]"))
                        print(f"üìä After aggressive scrolling: {new_count} conversations")
                        
                        if new_count <= initial_count:
                            no_change_count += 1
                        else:
                            no_change_count = 0
                else:
                    no_change_count = 0
                
                # Stop if no changes for several attempts
                if no_change_count >= max_no_change:
                    print(f"‚èπÔ∏è Stopping scroll after {max_no_change} attempts with no new conversations")
                    break
                
                initial_count = new_count
            
            final_count = len(driver.find_elements(By.XPATH, "//a[contains(@href, '/c/')]"))
            print(f"üéØ Final conversation count after scrolling: {final_count}")
            
            # If we still have a low count, try one more round
            if final_count < 500:  # If less than 500, try more
                print("üîÑ Low count detected, trying additional scrolling...")
                for i in range(20):
                    driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", sidebar)
                    time.sleep(1)
                
                final_count = len(driver.find_elements(By.XPATH, "//a[contains(@href, '/c/')]"))
                print(f"üìä After additional scrolling: {final_count} conversations")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error during scrolling: {e}")
    
    def _extract_conversations(self, driver) -> list:
        """Extract conversation data from the page."""
        try:
            # Get all conversation links
            conversation_links = driver.find_elements(By.XPATH, "//a[contains(@href, '/c/')]")
            
            conversations = []
            seen_ids = set()
            
            for link in conversation_links:
                try:
                    href = link.get_attribute('href')
                    if not href:
                        continue
                    
                    # Extract conversation ID
                    conversation_id = None
                    if '/c/' in href:
                        conversation_id = href.split('/c/')[-1].split('?')[0]
                    
                    if not conversation_id or conversation_id in seen_ids:
                        continue
                    
                    seen_ids.add(conversation_id)
                    
                    # Get title
                    title = link.text.strip()
                    if not title:
                        try:
                            parent = link.find_element(By.XPATH, "./..")
                            title = parent.text.strip()
                        except:
                            title = f"Conversation {conversation_id[:8]}"
                    
                    # Skip demo conversations
                    if 'demo' in title.lower() or 'demo' in conversation_id.lower():
                        continue
                    
                    conversations.append({
                        'id': conversation_id,
                        'title': title,
                        'url': href
                    })
                    
                except StaleElementReferenceException:
                    continue
                except Exception as e:
                    print(f"‚ö†Ô∏è Error extracting conversation: {e}")
                    continue
            
            return conversations
            
        except Exception as e:
            print(f"‚ùå Error extracting conversations: {e}")
            return []

def main():
    """Main function with unified login utility."""
    try:
        print("üöÄ Starting Improved Conversation Scraper...")
        
        # Initialize browser
        browser_manager = BrowserManager()
        driver = browser_manager.create_driver()
        
        if not driver:
            print("‚ùå Failed to create browser driver")
            return 1
        
        # Navigate to ChatGPT
        print("üåê Navigating to ChatGPT...")
        driver.get('https://chat.openai.com/')
        print("‚úÖ Navigated to ChatGPT")
        
        # Wait for page to load
        time.sleep(3)
        
        # Use unified login utility
        print("üîê Using unified login utility...")
        cookie_manager, login_handler = create_login_components('data/chatgpt_cookies.pkl')
        
        if not ensure_login_unified(driver, cookie_manager, login_handler):
            print("‚ùå Login failed")
            driver.quit()
            return 1
        
        print("‚úÖ Login successful!")
        
        # Extract conversations with improved scraper
        print("üìã Extracting conversations with aggressive scrolling...")
        scraper = ImprovedConversationScraper()
        conversations = scraper.get_conversation_list(driver)
        
        if conversations:
            print(f"üéâ Successfully found {len(conversations)} conversations!")
            
            # Save to file
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f'data/conversations/improved_scraper_{timestamp}.json'
            
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(conversations, f, indent=2, ensure_ascii=False)
            
            print(f"üíæ Saved to {output_file}")
            
            # Show first 15 conversations
            print("\nüìù First 15 conversations:")
            for i, conv in enumerate(conversations[:15]):
                title = conv.get('title', 'No title')
                conv_id = conv.get('id', 'No ID')
                print(f"  {i+1:2d}. {title} (ID: {conv_id})")
            
            if len(conversations) > 15:
                print(f"  ... and {len(conversations) - 15} more conversations")
            
        else:
            print("‚ùå No conversations found")
        
        # Close browser
        driver.quit()
        print("‚úÖ Browser closed")
        
        print("\nüéâ Improved scraper completed!")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 