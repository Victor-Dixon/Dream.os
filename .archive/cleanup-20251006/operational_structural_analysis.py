#!/usr/bin/env python3
"""
Agent-8 Operational Structural Analysis for SWARM Survey
=======================================================

Comprehensive analysis of src/ directory from operational perspective
for consolidation planning (683 ‚Üí ~250 files)
"""

import json
import os
from pathlib import Path


def analyze_src_structure():
    """Perform comprehensive operational analysis of src/ directory"""

    print("üîç AGENT-8 OPERATIONAL STRUCTURAL ANALYSIS")
    print("==========================================")
    print()

    src_path = Path("src")
    if not src_path.exists():
        print("‚ùå src/ directory not found")
        return

    print("üìä SRC/ DIRECTORY OPERATIONAL ANALYSIS")
    print("=" * 45)

    # 1. Directory Structure Analysis
    print("\nüèóÔ∏è  DIRECTORY STRUCTURE ANALYSIS:")
    print("-" * 35)

    directories = []
    files = []
    total_size = 0

    for root, dirs, filenames in os.walk(src_path):
        for d in dirs:
            directories.append(os.path.join(root, d))
        for f in filenames:
            filepath = os.path.join(root, f)
            files.append(filepath)
            try:
                total_size += os.path.getsize(filepath)
            except OSError:
                pass

    print(f"Total Directories: {len(directories)}")
    print(f"Total Files: {len(files)}")
    print(f"Total Size: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)")

    # 2. Directory Depth Analysis
    print("\nüìè DIRECTORY DEPTH ANALYSIS:")
    print("-" * 30)

    depths = {}
    for d in directories:
        rel_path = os.path.relpath(d, "src")
        depth = len(rel_path.split(os.sep))
        depths[depth] = depths.get(depth, 0) + 1

    for depth in sorted(depths.keys()):
        print(f"Depth {depth}: {depths[depth]} directories")

    # 3. File Type Distribution
    print("\nüìÑ FILE TYPE DISTRIBUTION:")
    print("-" * 28)

    extensions = {}
    for f in files:
        ext = os.path.splitext(f)[1].lower()
        extensions[ext] = extensions.get(ext, 0) + 1

    for ext, count in sorted(extensions.items(), key=lambda x: x[1], reverse=True):
        ext_name = ext if ext else "No extension"
        print(f"{ext_name}: {count} files")

    # 4. Largest Files Analysis
    print("\nüìà LARGEST FILES ANALYSIS:")
    print("-" * 27)

    file_sizes = []
    for f in files:
        try:
            size = os.path.getsize(f)
            file_sizes.append((f, size))
        except OSError:
            continue

    file_sizes.sort(key=lambda x: x[1], reverse=True)
    for filepath, size in file_sizes[:10]:
        rel_path = os.path.relpath(filepath, "src")
        print(f"{size:,} bytes - {rel_path}")

    # 5. Empty/Stub Files Analysis
    print("\nüö® POTENTIAL STUB/EMPTY FILES:")
    print("-" * 32)

    empty_files = []
    stub_files = []

    for filepath, size in file_sizes:
        if size == 0:
            empty_files.append(filepath)
        elif size < 100:
            try:
                with open(filepath, encoding="utf-8", errors="ignore") as f:
                    content = f.read()
                    if len(content.strip()) < 50:
                        stub_files.append((filepath, size, len(content.strip())))
            except:
                continue

    print(f"Empty files (0 bytes): {len(empty_files)}")
    for f in empty_files[:5]:
        print(f'  - {os.path.relpath(f, "src")}')

    print(f"\nPotential stub files (<100 bytes): {len(stub_files)}")
    for f, size, content_len in stub_files[:5]:
        print(f'  - {os.path.relpath(f, "src")} ({size} bytes, {content_len} chars)')

    # 6. Operational Complexity Assessment
    print("\n‚öôÔ∏è  OPERATIONAL COMPLEXITY ASSESSMENT:")
    print("-" * 38)

    avg_files_per_dir = len(files) / len(directories) if directories else 0
    print(f"Average files per directory: {avg_files_per_dir:.1f}")

    large_files = [f for f, s in file_sizes if s > 100000]
    print(f"Large files (>100KB): {len(large_files)}")

    # Directory naming analysis
    service_dirs = [d for d in directories if "service" in os.path.basename(d).lower()]
    core_dirs = [d for d in directories if "core" in os.path.basename(d).lower()]
    util_dirs = [
        d
        for d in directories
        if "util" in os.path.basename(d).lower() or "utils" in os.path.basename(d).lower()
    ]

    print(f"Service-related directories: {len(service_dirs)}")
    print(f"Core directories: {len(core_dirs)}")
    print(f"Utility directories: {len(util_dirs)}")

    print("\n‚úÖ STRUCTURAL ANALYSIS COMPLETE")
    print("üìä Findings ready for SWARM coordination")

    return {
        "total_files": len(files),
        "total_directories": len(directories),
        "total_size": total_size,
        "empty_files": len(empty_files),
        "stub_files": len(stub_files),
        "large_files": len(large_files),
        "service_dirs": len(service_dirs),
        "core_dirs": len(core_dirs),
        "util_dirs": len(util_dirs),
        "max_depth": max(depths.keys()) if depths else 0,
    }


if __name__ == "__main__":
    results = analyze_src_structure()

    # Save results for SWARM coordination
    with open("Agent-8_Structural_Analysis_Results.json", "w") as f:
        json.dump(results, f, indent=2)

    print("\nüíæ Results saved to: Agent-8_Structural_Analysis_Results.json")
